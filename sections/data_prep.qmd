```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from sklearn.metrics import pairwise_distances
from tqdm import tqdm
import seaborn as sns
import plotly.graph_objects as go
import json


transactions_df = pd.read_parquet("temp/transactions.parquet")
accounts_df = pd.read_parquet("temp/accounts.parquet")
non_transactional_df = pd.read_parquet("temp/non_transactional.parquet")
with open("temp/data_reduction.json", "r") as f:
    data_reduction = json.load(f)
```

# Data Preparation: Transactional Data

As we already prepared the non-transactional data in a previous section, we now focus on the transactional data. As the end goal is to have a single record per customer, we need to aggregate the transactional data. In addition, absolute temporal data such as transaction dates needs to be transformed into relative data, such as the number of months before the event of card issuance.

## Set artificial issue date for non-card holders

One crucial step in the data preparation process is to set an artificial card issue date for non-card holders. This date is necessary to align the transactional data of non-card holders with that of card holders. By setting an artificial card issue date, we can create a unified timeline for all customers, enabling a more accurate comparison of transactional behaviors across different groups. 

First we will explore the distribution of the months between account creation and card issuance to understand the typical timeline for card issuance after account creation.


```{python}
def add_months_since_account_to_card(df):
    """Add a column to the DataFrame with the number of months between account creation and card issuance."""
    df["months_since_account_to_card"] = df.apply(
        lambda row: (
            (
                row["card_issued"].to_period("M")
                - row["account_created"].to_period("M")
            ).n
            if pd.notnull(row["card_issued"]) and pd.notnull(row["account_created"])
            else np.nan
        ),
        axis=1,
    )
    return df
```

As we need enough history to make a valid comparison between card holders and non-card holders, we filter out non-card holders with less than 25 months of history. This ensures that we have a sufficient amount of data to analyze and compare the transactional behaviors of both groups. Here is the reasoning behind this threshold:

- **New Customer Period (12 months)**: We need at least one year of transactional history to capture the typical spending patterns of customers.
- **One Year of History (12 months)**: An additional year of data provides a more comprehensive view of transactional behaviors, allowing us to identify trends and patterns more accurately across seasons and economic cycles.
- **Lag Period (1 month)**: The month immediately preceding card issuance is excluded to avoid any potential bias caused by transactional changes due to the impending card issuance.

```{python}
def filter_clients_without_sufficient_history(
    non_transactional_df, min_history_months=25
):
    if "months_since_account_to_card" not in non_transactional_df.columns:
        non_transactional_df = add_months_since_account_to_card(non_transactional_df)

    count_before = len(non_transactional_df)
    filtered_df = non_transactional_df[
        non_transactional_df["months_since_account_to_card"].isnull()
        | (non_transactional_df["months_since_account_to_card"] >= min_history_months)
    ]
    print(
        f"Filtered out {count_before - len(filtered_df)} records with less than {min_history_months} months of history. "
        f"Percentage: {(count_before - len(filtered_df)) / count_before * 100:.2f}%."
    )
    return filtered_df


before_len = len(non_transactional_df)

non_transactional_w_sufficient_history_df = filter_clients_without_sufficient_history(
    non_transactional_df
)

data_reduction["Clients without sufficient history"] = -(
    before_len - len(non_transactional_w_sufficient_history_df)
)
del before_len
```

In this case roughly 10% of the non-card holders were filtered out due to insufficient history. This is a reasonable amount and will not impact the analysis significantly.

Next, we will explore the distribution of the months between account creation and card issuance for card holders to understand the typical timeline for card issuance after account creation.

```{python}
non_transactional_w_card_df = non_transactional_w_sufficient_history_df.dropna(
    subset=["card_issued"]
).copy()

plt.figure(figsize=(8, 6))
sns.histplot(
    non_transactional_w_card_df["months_since_account_to_card"], kde=True, bins=30
)
plt.title(
    "Distribution of Months from Account Creation to Card Issuance (for Card Holders)"
)
plt.xlabel("Months")
plt.ylabel("Count")
plt.grid(True)
plt.tight_layout()
plt.show()
```

The plot shows a right-skewed distribution, with the majority of card holders receiving their cards roughly 25 to 30 months after account creation. On the long-tail end, some clients receive their cards after 60 months or more.

After briefly exploring the distribution of the months between account creation and card issuance for card holders, we will now set the artificial card issuance date for non-card holders. This date will be used to align the transactional data of non-card holders with that of card holders, enabling a more accurate comparison of transactional behaviors across different groups.

The following approaches were considered to match non-card holders with card holders:

1. Looking at the distributions above extract the amount of history a buyer most likely has at the issue data of the card
2. For each non buyer, find a buyer which was active in a similar time window (Jaccard similarity on the Year-Month sets). Instead of looking at the full activity of a buyer, we only look at the pre-purchase activity as there is reason to believe that clients may change their patterns after purchasing date and therefore add unwanted bias.

The second approach is chosen as it is provides an intuitive way to match clients based on their activity which is not only explainable but also provides a way to match clients based on their behavior. It strikes a balance of not finding a perfect match but a good enough match to focus on the discriminative features of the data.

Both approaches have their advantages and disadvantages. The first approach is more straightforward and less computationally intensive, but it may not capture the nuances of client behavior. The second approach is more complex and computationally intensive but offers a more nuanced view of client activity, potentially leading to better matches.

## Match by similar transaction activity

The process emphasizes matching based on the timing of activity, rather than a wide array of characteristics. By identifying when both existing cardholders and non-cardholders interacted with the bank, we can infer a level of behavioral alignment that extends beyond mere transactional data. This alignment suggests a shared response to external conditions. Intuitively we are constructing tuples of non-card holders and card holders based on the similarity of their activity patterns but one of them is not a card holder yet.

**Assumption**: This assumes that clients active during similar periods might be influenced by the same economic and societal conditions, providing a more nuanced foundation for establishing connections between current cardholders and potential new ones.

### Construction of the Activity Matrix

To hold the needed information about every customer we create a so called activity matrix. The resolution of the activity matrix is a binary matrix where each row represents a client and each column represents a month. A value of 1 indicates activity in a given month, while 0 indicates inactivity. Therefore we concentrate on the periods during which clients engage with the bank in the form of transactions rather than the specifics of those transactions. Here is a step-by-step breakdown of the construction process:

1.  **Data Aggregation**: We start with transaction data, which records each client's interactions across various months. This data includes every transaction made by both current cardholders and non-cardholders.

2.  **Temporal Transformation**: Each transaction is associated with a specific date. These dates are then transformed into monthly periods, consolidating daily transactions into a monthly view of activity. This step simplifies the data, focusing on the presence of activity within each month rather than the specific dates or frequencies of transactions.

3.  **Matrix Structure**: The transformed data is arranged into a matrix format. Rows represent individual clients, identified by their account IDs. Columns correspond to monthly periods, spanning the entire range of months covered by the transaction data.

4.  **Activity Indication**: In the matrix, a cell value is set to indicate the presence of activity for a given client in a given month. If a client made one or more transactions in a month, the corresponding cell is marked to reflect this activity. The absence of transactions for a client in a month leaves the cell unmarked. Active months are represented by a '1', indicating the presence of transactions, while inactive months are denoted by a '0', indicating no transactions.

```{python}
def prepare_activity_matrix(transactions):
    """
    Create an activity matrix from transaction data.

    The function transforms transaction data into a binary matrix that indicates
    whether an account was active in a given month.

    Parameters:
    - transactions (pd.DataFrame): A DataFrame containing the transaction data.

    Returns:
    - pd.DataFrame: An activity matrix with accounts as rows and months as columns.
    """
    transactions["month_year"] = transactions["date"].dt.to_period("M")
    transactions["active"] = 1

    activity_matrix = transactions.pivot_table(
        index="account_id", columns="month_year", values="active", fill_value=0
    )

    activity_matrix.columns = [f"active_{str(col)}" for col in activity_matrix.columns]
    return activity_matrix


def plot_activity_matrix(activity_matrix):
    activity_matrix = activity_matrix.reindex(
        activity_matrix.sum(axis=1).sort_values(ascending=False).index # sort by activity across time
    )
    
    activity_matrix.columns = activity_matrix.columns.str.replace("active_", "")
    sparse_matrix = activity_matrix.astype(bool)
    plt.figure(figsize=(8, 8))
    sns.heatmap(sparse_matrix, cmap="binary", yticklabels=False, cbar=False)
    plt.title(f"Activity Matrix across all clients sorted by account creation date")
    plt.xlabel("Month-Year")
    plt.ylabel("Accounts")
    plt.tight_layout()

    active_patch = mpatches.Patch(color='black', label='Active')
    inactive_patch = mpatches.Patch(color='white', label='Not Active')
    plt.legend(handles=[active_patch, inactive_patch], loc='upper right')

    plt.show()


activity_matrix = prepare_activity_matrix(transactions_df)
plot_activity_matrix(activity_matrix.copy())
```

The heatmap provided offers a visual representation of the activity matrix for clients, depicting the levels of engagement over various periods. Clients are sorted by activity, with the most active clients at the top and the least active at the bottom.

There is a distinct diagonal pattern, indicating that newer accounts (those created more recently) perhaps have fewer periods of activity. This makes sense as these accounts have not had the opportunity to transact over the earlier periods displayed on the heatmap.

Also interesting are some gaps withing the activity of some clients. This could be due to a variety of reasons, such as seasonal spending patterns or changes in financial circumstances.

### Eligibility Criteria

After constructing the activity matrix, we check for eligibility of non-cardholders to be matched with cardholders. This ensures alignment for later model construction. The eligibility criteria are as follows:

1.  **Account History**: Non-cardholders must have an established history of interaction, with at least 25 months of history between account creation and card issuance (12 months (= New customer period) + 13 months (= one year of history) + 1 month (Lag period)) as described above.
2.  **Account Creation Date**: The account creation date of a non-cardholder must precede the card issuance date of the cardholder as this is a prerequisite for the matching process to work correctly when we set the issue date for non-card holders following the intuition that nobody can have a card before the account is created.

```{python}
ELIGIBILITY_THRESHOLD_HIST_MONTHS = 25


def check_eligibility_for_matching(non_cardholder, cardholder, verbose=False):
    """
    Determine if a non-cardholder is eligible for matching with a cardholder.

    This function checks whether the card issuance to a cardholder occurred at least
    25 months after the non-cardholder's account was created.

    Parameters:
    - non_cardholder (pd.Series): A data series containing the non-cardholder's details.
    - cardholder (pd.Series): A data series containing the cardholder's details.
    - verbose (bool): If True, print detailed eligibility information. Default is False.

    Returns:
    - bool: True if the non-cardholder is eligible for matching, False otherwise.
    """
    if cardholder["card_issued"] <= non_cardholder["account_created"]:
        return False

    period_diff = (
        cardholder["card_issued"].to_period("M")
        - non_cardholder["account_created"].to_period("M")
    ).n

    if verbose:
        print(
            f"Card issued: {cardholder['card_issued']}, Account created: {non_cardholder['account_created']}, Period diff: {period_diff}, Eligible: {period_diff >= ELIGIBILITY_THRESHOLD_HIST_MONTHS}"
        )

    return period_diff >= ELIGIBILITY_THRESHOLD_HIST_MONTHS
```

### Matching Process

Next up we will implement the matching process. Our matching utilizes the Jaccard similarity index to compare activity patterns: We compare a vector representing an existing cardholder's monthly activity against a matrix of non-cardholders' activity patterns. Here we only consider the activity from the first transaction period across all customers to the card issue date.

The Jaccard similarity index is calculated as the intersection of active months divided by the union of active months between the two clients. This index ranges from 0 to 1, with higher values indicating greater overlap in activity patterns.

$$J(A, B) = \frac{|A \cap B|}{|A \cup B|}$$

The function `select_non_cardholders` randomly selects a non-cardholder match for a cardholder from the top N eligible candidates. The selection process is based on the Jaccard similarity scores calculated between the cardholder and non-cardholders. The function performs the following steps:

1. **Sorting by Similarity**: The function sorts the Jaccard distances between a cardholder and non-cardholders to identify the top N similar non-cardholders.
2. **Random Selection**: From the top N similar non-cardholders, the function randomly selects one non-cardholder match for the cardholder. This random selection helps avoid bias and ensures a fair matching process.

```{python}
def select_non_cardholders(
    distances,
    eligible_non_cardholders,
    matches,
    matched_applicants,
    cardholder,
    without_card_activity,
    top_n,
):
    """
    Randomly select a non-cardholder match for a cardholder from the top N eligible candidates.

    Parameters:
    - distances (np.array): An array of Jaccard distances between a cardholder and non-cardholders.
    - eligible_non_cardholders (list): A list of indices for non-cardholders who are eligible for matching.
    - matches (list): A list to which the match will be appended.
    - matched_applicants (set): A set of indices for non-cardholders who have already been matched.
    - cardholder (pd.Series): The data series of the current cardholder.
    - without_card_activity (pd.DataFrame): A DataFrame of non-cardholders without card issuance.
    - top_n (int): The number of top similar non-cardholders to consider for matching.

    Returns:
    - None: The matches list is updated in place with the selected match (Object by reference).
    """
    eligible_distances = distances[eligible_non_cardholders]
    sorted_indices = np.argsort(eligible_distances)[:top_n]

    if sorted_indices.size > 0:
        selected_index = np.random.choice(sorted_indices)
        actual_selected_index = eligible_non_cardholders[selected_index]

        if actual_selected_index not in matched_applicants:
            matched_applicants.add(actual_selected_index)
            applicant = without_card_activity.iloc[actual_selected_index]
            similarity = 1 - eligible_distances[selected_index]

            matches.append(
                (cardholder["client_id"], applicant["client_id"], similarity)
            )
```

The function `match_cardholders_with_non_cardholders` brings together the data preparation, matching process, and match selection steps. It performs the following operations:

1. **Data Preparation**: The function prepares the activity matrix and splits the non-cardholders into two groups: those with and without cards.
2. **Matching Process**: For each cardholder, the function calculates the Jaccard similarity between their activity pattern and those of eligible non-cardholders. It then selects the top N similar non-cardholders and randomly assigns one match per cardholder.
3. **Match Selection**: The function selects a non-cardholder match for each cardholder based on the Jaccard similarity scores. It ensures that each non-cardholder is matched only once and that the top N similar non-cardholders are considered for matching.
   1. The selection among the top N similar non-cardholders is done randomly to avoid bias. This process is defined in the `select_non_cardholders` function.
   2. The function also checks for the eligibility as defined above.
   3. If no eligible non-cardholders are found, the function prints a warning message.
4. **Output**: The function returns a list of tuples containing the matched cardholder and non-cardholder client IDs along with their similarity scores.

```{python}
def match_cardholders_with_non_cardholders(non_transactional, transactions, top_n=5):
    """
    Match cardholders with non-cardholders based on the similarity of their activity patterns.

    The function creates an activity matrix, identifies eligible non-cardholders, calculates
    the Jaccard similarity to find matches, and randomly selects one match per cardholder
    from the top N similar non-cardholders.

    Parameters:
    - non_transactional (pd.DataFrame): A DataFrame containing non-cardholders.
    - transactions (pd.DataFrame): A DataFrame containing transactional data.
    - top_n (int): The number of top similar non-cardholders to consider for matching.

    Returns:
    - list: A list of tuples with the cardholder and matched non-cardholder client IDs and similarity scores.
    """
    with_card = non_transactional[non_transactional["card_issued"].notna()]
    without_card = non_transactional[non_transactional["card_issued"].isna()]

    activity_matrix = prepare_activity_matrix(transactions)

    with_card_activity = with_card.join(activity_matrix, on="account_id", how="left")
    without_card_activity = without_card.join(
        activity_matrix, on="account_id", how="left"
    )

    matched_non_cardholders = set()
    matches = []

    for idx, cardholder in tqdm(
        with_card_activity.iterrows(),
        total=len(with_card_activity),
        desc="Matching cardholders",
    ):
        issue_period = cardholder["card_issued"].to_period("M")
        eligible_cols = [
            col
            for col in activity_matrix
            if col.startswith("active") and pd.Period(col.split("_")[1]) <= issue_period
        ]

        if not eligible_cols:
            print(
                f"No eligible months found for cardholder client_id {cardholder['client_id']}."
            )
            continue
        
        cardholder_vector = cardholder[eligible_cols].values.reshape(1, -1)
        non_cardholder_matrix = without_card_activity[eligible_cols].values
        
        cardholder_vector = np.where(cardholder_vector > 0, 1, 0).astype(bool)
        non_cardholder_matrix = np.where(non_cardholder_matrix > 0, 1, 0).astype(bool)

        assert (
            cardholder_vector.shape[1] == non_cardholder_matrix.shape[1]
        ), "Dimension mismatch between cardholder and applicant activity matrix."

        distances = pairwise_distances(
            cardholder_vector, non_cardholder_matrix, 
            metric="jaccard", n_jobs=-1 
        ).flatten()
        eligible_non_cardholders = [
            i
            for i, applicant in without_card_activity.iterrows()
            if check_eligibility_for_matching(applicant, cardholder)
            and i not in matched_non_cardholders
        ]

        if eligible_non_cardholders:
            select_non_cardholders(
                distances,
                eligible_non_cardholders,
                matches,
                matched_non_cardholders,
                cardholder,
                without_card_activity,
                top_n,
            )
        else:
            print(
                f"No eligible non-cardholders found for cardholder client_id {cardholder['client_id']}."
            )

    return matches
```

The matching process is executed, and the results are stored in the `matched_non_card_holders_df` DataFrame. The percentage of clients with a card issued before and after matching is calculated to assess the impact of the matching process. We expect the percentage of clients with a card issued to increase by 100% after matching, as each non-cardholder should be matched with a cardholder.

```{python}
matched_non_card_holders_df = match_cardholders_with_non_cardholders(
    non_transactional_w_sufficient_history_df, transactions_df
)

percentage_before_matching = non_transactional_w_sufficient_history_df["card_issued"].notna().mean() * 100
print(f"Percentage of clients with card issued: {percentage_before_matching:.2f}%")
```

Last but not least we set the artificial card issue date for each non-cardholder based on the matching results.

```{python}
def set_artificial_issue_dates(non_transactional_df, matches):
    """
    Augment the non-transactional DataFrame with artificial card issue dates based on matching results.

    Each matched non-cardholder is assigned a card issue date corresponding to their matched
    cardholder. The 'has_card' flag for each non-cardholder is updated accordingly.

    Parameters:
    - non_transactional_df (pd.DataFrame): The DataFrame of non-cardholders to augment.
    - matches (list): A list of tuples containing the matched cardholder and non-cardholder IDs and similarity scores.

    Returns:
    - pd.DataFrame: The augmented DataFrame with artificial card issue dates.
    """
    augmented_df = non_transactional_df.copy()
    augmented_df["has_card"] = True

    for cardholder_id, non_cardholder_id, _ in matches:
        card_issue_date = augmented_df.loc[
            augmented_df["client_id"] == cardholder_id, "card_issued"
        ].values[0]
        augmented_df.loc[
            augmented_df["client_id"] == non_cardholder_id, ["card_issued", "has_card"]
        ] = [card_issue_date, False]

    return augmented_df

matched_non_card_holders_w_issue_date_df = set_artificial_issue_dates(
    non_transactional_w_sufficient_history_df, matched_non_card_holders_df
)

percentage_after_matching = matched_non_card_holders_w_issue_date_df["card_issued"].notna().mean() * 100
assert np.isclose(percentage_after_matching, percentage_before_matching * 2), "Percentage of clients with card issued after matching should be double the initial percentage."
print(f"Percentage of clients with card issued after matching: {percentage_after_matching:.2f}%")
print(f"Percentage without card issued after matching: {(1 - percentage_after_matching / 100) * 100:.2f}%")
```

After each non-cardholder got the artifical card issued date assigned we drop the remaining non-cardholders without a match.

```{python}
before_len = len(matched_non_card_holders_w_issue_date_df)

matched_non_card_holders_w_issue_date_df = (
    matched_non_card_holders_w_issue_date_df.dropna(subset=["card_issued"])
)

data_reduction["Non-cardholders without match"] = -(
    before_len - len(matched_non_card_holders_w_issue_date_df)
)

print(f"Filtered out {before_len - len(matched_non_card_holders_w_issue_date_df)} non-cardholders without a match.")
del before_len
```

In total 83% of the non-card holders were filtered out due to ineligibility or not being matched with a card holder.

## Monthly Summary of Transactions

After matching cardholders with non-cardholders and setting artificial card issue dates, we aggregate the transactional data on a monthly basis to remove the transactional nature of the data. The monthly aggregation makes sense for multiple reasons:

- Monthly aggregation standardizes the time frame across which we analyze transactions, allowing us to compare transactional behaviors consistently across all accounts.
- Aggregating data on a monthly level illuminates patterns that daily data might obscure. It enables us to discern trends over a broader time scale, capturing cyclical behaviors, seasonal effects, and response to macroeconomic events.
- Daily transaction data can be "noisy" with random fluctuations. By considering monthly totals and averages, we reduce this noise, revealing underlying trends more clearly.

The function `aggregate_transactions_monthly` simplifies financial transactions by summarizing them every month for each account. Here's a simplified explanation of how it works:

1. **Sorting Transactions**: First, the function arranges the transactions chronologically by `account_id` and `date` within the `transactions_df` DataFrame. This helps in organizing transactions for each account by date.

2. **Monthly Grouping**: It converts each transaction's date into a monthly period. This categorizes transactions by the month and year they occurred, making it easier to group them monthly.

3. **Aggregation of Monthly Data**: The function groups these transactions by `account_id` and the `month` column. For each group, it calculates:
   - `volume`: Total transaction amount for the month.
   - `total_abs_amount`: Total of absolute values of all transactions, showing the total money movement regardless of direction.
   - `transaction_count`: Number of transactions to show how active the account was.
   - Counts of positive and negative transactions, indicating money coming in and going out.
   - Other statistics like average, median, minimum, maximum, and standard deviation of transaction amounts, which provide insights into how transaction amounts vary.
   - Counts of different transaction types, operations, and symbols, showing the variety of transactions.

4. **Cumulative Balance Calculation**: Finally, the function calculates a running total of the `volume` to track how the account balance changes over time.

This method is effective for understanding the financial behavior of accounts on a monthly basis, helping in further analyses and model building.

```{python}
def aggregate_transactions_monthly(df):
    """
    Aggregate financial transaction data on a monthly basis per account.

    Parameters:
    - df (pd.DataFrame): DataFrame containing financial transaction data with 'account_id', 'date', and other relevant columns.

    - validate (bool): If True, validate the aggregated data. Default is True.

    Returns:
    - pd.DataFrame: Monthly aggregated financial transaction data per account.
    """
    df_sorted = df.sort_values(by=["account_id", "date"]) # sort by account_id and date to ensure correct running balance calculation
    df_sorted["month"] = df_sorted["date"].dt.to_period("M")

    monthly_aggregated_data = (
        df_sorted.groupby(["account_id", "month"])
        .agg(
            volume=("amount", "sum"),
            total_abs_amount=("amount", lambda x: x.abs().sum()),
            transaction_count=("amount", "count"),
            positive_transaction_count=("amount", lambda x: (x >= 0).sum()),
            negative_transaction_count=("amount", lambda x: (x < 0).sum()),
            average_amount=("amount", "mean"),
            median_amount=("amount", "median"),
            min_amount=("amount", "min"),
            max_amount=("amount", "max"),
            std_amount=("amount", "std"),
            type_count=("transaction_type", "nunique"),
            operation_count=("operation", "nunique"),
            k_symbol_count=("k_symbol", "nunique"),
        )
        .reset_index()
        .sort_values(by=["account_id", "month"])
    )
    
    monthly_aggregated_data["balance"] = monthly_aggregated_data.groupby("account_id")[
        "volume"
    ].cumsum()
    
    return monthly_aggregated_data

agg_transactions_monthly_df = aggregate_transactions_monthly(transactions_df)
agg_transactions_monthly_df.describe()
```

The `validate_monthly_aggregated_transactions` function is invoked to ensure the integrity and correctness of the aggregated data through several assertions:

1. The balance should consistently increase or decrease based on whether the total monthly transaction volume is positive or negative, respectively.
2. For each account, the balance in the first month should equal the total transaction volume of that month.
3. The sum of positive and negative transaction counts must equal the total transaction count for each month.
4. The number of unique accounts in the aggregated data should match that in the original dataset.
5. The final balances of accounts in the aggregated data should closely match their last recorded transactions in the original dataset.

```{python}
def validate_monthly_aggregated_transactions(aggregated_data, original_df):
    """
    Validate the integrity and correctness of aggregated monthly financial transactions.

    Parameters:
    - aggregated_data (pd.DataFrame): Aggregated monthly transaction data.
    - original_df (pd.DataFrame): Original dataset of financial transactions.

    Raises:
    - AssertionError: If validation conditions are not met.
    """
    # Assertion 1: Balance should consistently increase or decrease based on total monthly transaction volume
    assert (aggregated_data["volume"] >= 0).all() == (
        aggregated_data["balance"].diff() >= 0
    ).all(), "If the total amount is positive, the balance should go up."
    assert (aggregated_data["volume"] < 0).all() == (
        aggregated_data["balance"].diff() < 0
    ).all(), "If the total amount is negative, the balance should go down."

    # Assertion 2: Balance in the first month should equal the total transaction volume of that month
    first_month = aggregated_data.groupby("account_id").nth(0)
    assert (
        first_month["volume"] == first_month["balance"]
    ).all(), "The balance should equal the volume for the first month."

    # Assertion 3: The sum of positive and negative transaction counts should equal the total transaction count
    assert (
        aggregated_data["positive_transaction_count"]
        + aggregated_data["negative_transaction_count"]
        == aggregated_data["transaction_count"]
    ).all(), "The sum of positive and negative transaction counts should equal the total transaction count."

    # Assertion 4: The number of unique accounts in the aggregated data should match that in the original dataset
    assert (
        aggregated_data["account_id"].nunique() == original_df["account_id"].nunique()
    ), "The number of unique account_ids in the aggregated DataFrame should be the same as the original DataFrame."

    # Assertion 5: The final balances of accounts in the aggregated data should closely match their last recorded transactions in the original dataset
    assert (
        pd.merge(
            aggregated_data.groupby("account_id")
            .last()
            .reset_index()[["account_id", "balance"]],
            original_df[
                original_df.groupby("account_id")["date"].transform("max")
                == original_df["date"]
            ][["account_id", "balance"]],
            on="account_id",
            suffixes=("_final", "_last"),
        )
        .apply(
            lambda x: np.isclose(x["balance_final"], x["balance_last"], atol=5), axis=1 # allow for small differences due to floating point precision
        )
        .any()
    ), "Some accounts' final balances do not match their last transactions."


validate_monthly_aggregated_transactions(agg_transactions_monthly_df, transactions_df)
```

# Exploratory Data Analysis: Aggregated Monthly Transactions

Further we explore the aggregated monthly transactions to gain insights into the financial behavior of accounts over time. We will visualize the monthly transaction volume, balance, and number of transactions to understand how these metrics evolve over time.

## Monthly Balance Difference and Volume

The `plot_monthly_balance_diff_and_volume` function visualizes the monthly balance difference and volume for a specific account. The balance difference is calculated as the difference between the current month's balance and the previous month's balance. This metric helps identify the impact of monthly transactions on the account balance. The volume represents the total transaction amount for each month.

```{python}
def plot_monthly_balance_diff_and_volume(
    transactions_monthly, account_id 
):
    account_transactions = transactions_monthly[
        transactions_monthly["account_id"] == account_id
    ].sort_values(by="month")
    account_transactions["balance_diff"] = account_transactions["balance"].diff()

    plt.figure(figsize=(9.5, 6))

    plt.plot(
        account_transactions["month"].astype(str),
        account_transactions["balance_diff"],
        marker="o",
        label="Balance Difference",
    )
    plt.plot(
        account_transactions["month"].astype(str),
        account_transactions["volume"],
        marker="x",
        linestyle="--",
        label="Volume",
    )

    plt.title(f"Monthly Balance Difference and Volume for Account {account_id}")
    plt.xlabel("Month")
    plt.ylabel("Value")
    plt.xticks(rotation=90, fontsize=7)
    plt.yticks(fontsize=8)
    plt.legend()
    plt.grid(True)
    plt.show()


plot_monthly_balance_diff_and_volume(agg_transactions_monthly_df, 2)
```

This plot gives a clear picture of how money moves in and out of an account each month and how these movements affect the overall balance. It does this by showing two things:

- **Balance Difference**: This line shows whether the account balance went up or down each month. If the line goes up, it means the account gained money that month. If it goes down, the account lost money.
- **Volume**: This line shows the total amount of money that moved in the account each month, regardless of whether it was coming in or going out.

There is a direct link between the amount of money moved (volume) and changes in the account balance. High incoming money should lead to an uptick in the balance, and lots of outgoing money should lead to a downturn. It further confirms the aggregation made in the previous step was correct.

## Monthly Balance and Volume

Instead of the difference in balance, we can also look at the monthly balance and volume directly. The `plot_monthly_transactions_balance_and_volume` function visualizes the monthly transactions and balance for a specific account.

```{python}
def plot_monthly_transactions_balance_and_volume(agg_transactions_monthly, account_id):
    account_transactions = agg_transactions_monthly[
        agg_transactions_monthly["account_id"] == account_id
    ]

    plt.figure(figsize=(9.5, 6))

    plt.plot(
        account_transactions["month"].astype(str),
        account_transactions["volume"],
        marker="o",
        label="Volume",
    )
    plt.plot(
        account_transactions["month"].astype(str),
        account_transactions["balance"],
        marker="x",
        linestyle="--",
        label="Balance",
    )

    plt.title(f"Monthly Transactions and Balance for Account {account_id}")
    plt.xlabel("Month")
    plt.ylabel("Value")
    plt.xticks(rotation=90, fontsize=7)
    plt.yticks(fontsize=8)
    plt.legend()
    plt.grid(True)
    plt.show()


plot_monthly_transactions_balance_and_volume(agg_transactions_monthly_df, 2)
```

This visualization offers a snapshot of an account’s activity over time by comparing money movement each month with the overall account balance. Similarly to the previous plot, it shows two key metrics:

- **Volume**: How much money came in or went out of the account each month. Incoming money is shown as up, and outgoing money as down.
- **Balance**: The total money in the account at the end of each month, showing how it's changed over time due to the monthly transactions.

It shows how the monthly money movement impacts the account's growing or shrinking balance. For example, a few months of high income should visibly increase the balance. It further validates the aggregation made in the previous step.

## Deliverable: Closer Look at Account 14

Let's take a closer look at the monthly transactions, balance, and volume for account 14 as requested by the task.

```{python}
plot_monthly_transactions_balance_and_volume(agg_transactions_monthly_df, 14)
```

Account 14 shows a rather conservative transaction history. The spending habits are all withing range of 10k to -10k per month. We can see little volatility, the account shows a slight trend of growing.

## Deliverable: Closer Look at Account 18

Let's also examine the monthly transactions, balance, and volume for account 18.

```{python}
plot_monthly_transactions_balance_and_volume(agg_transactions_monthly_df, 18)
```

Account 18 paints a different picture in comparison to account 14.

The volatility here is a lot higher, indicating a potential for a business account or high income household. Especially March 1994 to December 1994 show some volatile transaction habits.

Looking at the balance and volume per month for the accounts 14 and 18 we can notice different patterns. Account 14 shows a rather conservative transaction history with little volatility and a slight trend of growing. Account 18, on the other hand, shows a lot more volatility, indicating a potential business account or high-income household. This highlights the importance of understanding the financial behavior of accounts to identify patterns and trends that can inform decision-making. Ultimately, this is the job of the models we will build in the next steps.

# Pivot Transactions: Rolling Up to Monthly Aggregates

Now we pivot the aggregated transaction data to have each account as a row and the months leading up to card issuance as columns. This transformation aligns with the goal for a single record per account, summarizing transactional behavior in the months before card issuance.

The `pivot_transactions` function aggregates monthly transaction data and merges it with non-transactional account data. It focuses on the time frame leading up to the card issuance, filtering transactions based on a specified range of months before card issuance and aggregating various transaction metrics.

We are mainly interested in the time frame 2 months to 13 months before card issuance. This range allows us to capture transactional behavior in the year leading up to the card issuance, ignoring the month directly before the card issuance to avoid any potential bias from the card issuance itself.

```{python}
def pivot_transactions(
    non_transactional, transactions_monthly, months_before_card_range=(2, 13)
):
    """
    Aggregate monthly transaction data and merge it with non-transactional account data,
    focusing on the time frame leading up to the card issuance.

    This function merges monthly transaction data with non-transactional data to associate each
    transaction with the respective account and card issued date. It then filters transactions based
    on a specified range of months before card issuance and aggregates various transaction metrics.

    Parameters:
    - non_transactional (pd.DataFrame): A DataFrame containing non-transactional account data. This is only used to map card issuance dates to transactions.
    - transactions_monthly (pd.DataFrame): A DataFrame containing monthly transaction data.
    - months_before_card_range (tuple): A tuple specifying the inclusive range of months before card
                                        issuance to filter the transactions for aggregation.

    The aggregation includes the sum of volume and transaction counts, as well as the mean and other
    statistical measures of transaction amounts, for each account within the specified months before
    card issuance.

    The resulting DataFrame is pivoted to have 'account_id' as rows and the months before card
    issuance as columns, with aggregated metrics as values. Column names are constructed to
    describe the month and the metric represented.

    Returns:
    - pd.DataFrame: The final aggregated and pivoted dataset ready for analysis, with each row
                    representing an account and each column a specific metric in the months before
                    card issuance.
    """
    merged_df = transactions_monthly.merge(
        non_transactional[["account_id"]], on="account_id"
    )

    merged_df["card_issued_date"] = merged_df["account_id"].map(
        non_transactional.set_index("account_id")["card_issued"]
    )
    merged_df["months_before_card"] = merged_df.apply(
        lambda row: (row["card_issued_date"].to_period("M") - row["month"]).n, axis=1
    )

    start_month, end_month = months_before_card_range
    filtered_df = merged_df.query(f"{start_month} <= months_before_card <= {end_month}")

    aggregated_data = (
        filtered_df.groupby(["account_id", "months_before_card"])
        .agg(
            {
                "volume": "sum",
                "total_abs_amount": "sum",
                "transaction_count": "sum",
                "positive_transaction_count": "sum",
                "negative_transaction_count": "sum",
                "average_amount": "mean",
                "median_amount": "median",
                "min_amount": "min",
                "max_amount": "max",
                "std_amount": "std",
                "type_count": "sum",
                "operation_count": "sum",
                "k_symbol_count": "sum",
                "balance": "mean",
            }
        )
        .reset_index()
    )

    pivoted_data = aggregated_data.pivot(
        index="account_id", columns="months_before_card"
    )
    
    pivoted_data.columns = [
        "_".join(["M", str(col[1]), col[0]]) for col in pivoted_data.columns.values
    ]
    return pivoted_data.reset_index()

transactions_pivoted_df = pivot_transactions(
    matched_non_card_holders_w_issue_date_df, agg_transactions_monthly_df
)
transactions_pivoted_df.describe()
```

# Merge everything together

Finally, we merge the non-transactional data with the pivoted transactional data to create the final golden record. This record contains all relevant information for each account, including the aggregated transactional data for each month leading up to the card issuance date.

The resulting DataFrame has one row per account, with columns representing various metrics for each month before card issuance along with non-transactional data like client and account IDs, card issuance dates, and other relevant information.

We can merge the non-transactional data with the pivoted transactional data using the `account_id` as the common key. As each transaction is linked to an account, this key ensures that the transactional data is correctly associated with the respective account.

```{python}
golden_record_df = matched_non_card_holders_w_issue_date_df.merge(
    transactions_pivoted_df, on="account_id", how="left" # left join as we 
)

data_reduction["Final Golden Record"] = len(golden_record_df)
golden_record_df.head()
```

Looking at the first few rows of the final golden record, we can see the aggregated transactional data for each account, with columns representing various metrics for each month leading up to the card issuance date.

Additionally we can verify the uniqueness of `client_id` and `account_id` in the final DataFrame.

```{python}
assert golden_record_df[
    "client_id"
].is_unique, "Each client_id should appear exactly once in the final DataFrame."

assert golden_record_df[
    "account_id"
].is_unique, "Each account_id should appear exactly once in the final DataFrame."
```

```{python}
plt.figure()
plt.title("Number of Clients by Card Issuance Status")
sns.countplot(x="has_card", data=golden_record_df)
plt.xlabel("Card Issued")
plt.ylabel("Count")
plt.show()
```

Looking at the card issuance status we can see that the number of clients with a card issued is equal to the number of clients without a card issued.

```{python}
plt.figure()
plt.title("Distribution of Card Issuance Dates")
sns.histplot(
    golden_record_df, x="card_issued", hue="has_card", kde=True, bins=30, alpha=0.5
)
plt.xlabel("Card Issuance Date")
plt.ylabel("Count")
plt.show()
```

The distribution of card issuance dates shows that the card issuance process was spread out over time, with an expected identical distribution for clients with and without cards issued. This makes sense as we set the artificial card issue date for each non-cardholder based on the matching results.

# Data Reduction Summary

The following waterfall chart visualizes the data reduction process, highlighting the number of records retained or lost at each stage.

```{python}
data_reduction_df = pd.DataFrame(
    list(data_reduction.items()), columns=["Category", "Amount"]
)
colors = ["skyblue" if amt >= 0 else "orange" for amt in data_reduction_df["Amount"]]

fig = go.Figure(
    go.Waterfall(
        name="20",
        orientation="v",
        measure=["relative"] * (len(data_reduction_df) - 1) + ["total"],
        x=data_reduction_df["Category"],
        textposition="outside",
        text=[f"{amt:,.0f}" for amt in data_reduction_df["Amount"]],
        y=data_reduction_df["Amount"],
        connector={"line": {"color": "black", "width": 2}},
        decreasing={"marker": {"color": "orange"}},
        increasing={"marker": {"color": "skyblue"}},
        totals={"marker": {"color": "skyblue"}},
    )
)

fig.update_layout(
    title="Enhanced Data Reduction Waterfall Chart",
    xaxis=dict(title="Category"),
    yaxis=dict(title="Amount", range=[0, 5500]),
    waterfallgap=0.3,
)
fig.show()
```

The waterfall chart provides a visual representation of the data reduction process, illustrating the number of records retained or lost at each stage. The chart shows the reduction in the number of records from the initial dataset to the final golden record, highlighting the impact of each step in the data preparation pipeline:

- **Initial Dataset**: The starting point with the full dataset of 4500 accounts/records.
- **Junior Accounts**: The removal of junior accounts, reducing the dataset by 145 records.
- **Clients without sufficient history**: The elimination of clients without sufficient transactional history, resulting in a reduction of 419 records.
- **Non-cardholders without match**: The filtering out of non-cardholders without a match, leading to a decrease of 3'280 records.
- **Final Golden Record**: The final dataset with 656 records, each representing a unique account with aggregated transactional data for each month leading up to the card issuance date.

# Exploratory Data Analysis: Golden Record

With the final golden record in hand, we can now perform exploratory data analysis to gain insights into the financial behavior of cardholders and non-cardholders.

## Comparing Cardholders and Non-Cardholders

We will focus on comparing the financial behavior of cardholders and non-cardholders to identify any significant differences in their transactional patterns. This analysis can help us understand how cardholders differ from non-cardholders in terms of transaction volume, balance, and other financial metrics giving us an impression of the financial behavior of cardholders and non-cardholders.

### Trends in Financial Metrics

The function `plot_trends_with_medians` generates line graphs for average monthly values and annotates medians for specified ranges. This visualization helps identify trends in financial metrics over time and highlights the median values for specific periods, providing insights into the distribution of values.

```{python}
golden_cardholders = golden_record_df[golden_record_df["has_card"]]
golden_non_cardholders = golden_record_df[~golden_record_df["has_card"]]


def plot_trends_with_medians(
    cardholders, non_cardholders, columns, title, median_ranges
):
    """
    Plots line graphs for average monthly values and annotates medians for specified ranges,
    adjusting x-axis indices to match the month sequence from the start.

    Parameters:
    - cardholders (pd.DataFrame): DataFrame containing data for cardholders.
    - non_cardholders (pd.DataFrame): DataFrame containing data for non-cardholders.
    - columns (list of str): List of column names ordered by time.
    - title (str): Title for the plot.
    - median_ranges (list of tuples): Each tuple contains start and end indices for calculating medians.
    """
    cardholder_avgs = cardholders[columns].mean()
    non_cardholder_avgs = non_cardholders[columns].mean()

    months = list(range(1, 1 + len(columns)))
    plt.figure()
    plt.plot(
        months,
        cardholder_avgs.values,
        marker="o",
        linestyle="-",
        color="blue",
        label="Cardholders",
    )
    plt.plot(
        months,
        non_cardholder_avgs.values,
        marker="o",
        linestyle="-",
        color="orange",
        label="Non-Cardholders",
    )

    for start, end in median_ranges:
        median_cardholder = cardholders[columns[start : end + 1]].median().median()
        median_non_cardholder = (
            non_cardholders[columns[start : end + 1]].median().median()
        )
        plt.hlines(
            median_cardholder,
            months[start],
            months[end],
            colors="darkblue",
            linestyles="--",
            label=f"Median {start+1}-{end+1} (Cardholders): {median_cardholder:.2f}",
        )
        plt.hlines(
            median_non_cardholder,
            months[start],
            months[end],
            colors="red",
            linestyles="--",
            label=f"Median {start+1}-{end+1} (Non-Cardholders): {median_non_cardholder:.2f}",
        )

    plt.title(title)
    plt.xlabel("Month")
    plt.ylabel("Value")
    plt.legend()
    plt.grid(True)
    plt.xticks(months, labels=[f"M_{month}" for month in months])  # Proper month labels
    plt.show()
```

### Monthly Balance Trends

```{python}
plot_trends_with_medians(
    golden_cardholders,
    golden_non_cardholders,
    [f"M_{i}_balance" for i in range(2, 14)],
    "Monthly Balance Trends",
    [(0, 2), (9, 11)]
)
```

Starting with the monthly balance trends, we can observe how the average balance changes over time for cardholders and non-cardholders. The line graph shows the average monthly balance for each group, with annotations indicating the median balance for specific periods.

It is interesting to note that the median balance for cardholders is consistently higher than that of non-cardholders, indicating a potential difference in financial stability or spending habits between the two groups over time.

### Monthly Volume Trends

```{python}
plot_trends_with_medians(
    golden_cardholders,
    golden_non_cardholders,
    [f"M_{i}_volume" for i in range(2, 14)],
    "Monthly Volume Trends",
    median_ranges,
)
```

The monthly volume trends show the average monthly transaction volume for cardholders and non-cardholders over time. The line graph illustrates how the transaction volume changes each month, with annotations highlighting the median volume for specific periods.

The median volume for cardholders is higher than that of non-cardholders, indicating a potential difference in transactional activity or spending patterns between the two groups. However, when sole looking at the volume, the difference is not as pronounced as with the balance and shows very volatile behavior. Generally this could come from the fact that the volume is the sum of all transactions, which can be naturally very volatile.

### Monthly Transaction Count Trends

```{python}
plot_trends_with_medians(
    golden_cardholders,
    golden_non_cardholders,
    [f"M_{i}_transaction_count" for i in range(2, 14)],
    "Monthly Transaction Count Trends",
    median_ranges,
)
```


The monthly transaction count trends show the average number of transactions per month for cardholders and non-cardholders over time. The line graph displays how the transaction count changes each month, with annotations indicating the median count for specific periods.

The median transaction count for cardholders is higher than that of non-cardholders, suggesting a difference in transactional activity or spending habits between the two groups. This is in line with the volume trends, indicating that cardholders tend to have more transactions on average than non-cardholders.

### Monthly Positive and Negative Transaction Count Trends

```{python}
plot_trends_with_medians(
    golden_cardholders,
    golden_non_cardholders,
    [f"M_{i}_positive_transaction_count" for i in range(2, 14)],
    "Monthly Positive Transaction Count Trends",
    median_ranges,
)
```

The monthly transaction count trends show the average number of transactions per month for cardholders and non-cardholders over time. The line graph displays how the transaction count changes each month, with annotations indicating the median count for specific periods.

The median transaction count for cardholders is only slightly higher than that of non-cardholders, indicating that the difference in transactional activity is not as pronounced for positive transactions. This suggests that both groups have similar patterns of money coming in each month.

```{python}
plot_trends_with_medians(
    golden_cardholders,
    golden_non_cardholders,
    [f"M_{i}_negative_transaction_count" for i in range(2, 14)],
    "Monthly Negative Transaction Count Trends",
    median_ranges,
)
```

The monthly negative transaction count trends show the average number of transactions per month for cardholders and non-cardholders over time. The line graph displays how the transaction count changes each month, with annotations indicating the median count for specific periods.

The picture is pretty similar to the positive transaction count trends, indicating that both groups have similar patterns of money going out each month. This suggests that the difference in transactional activity between cardholders and non-cardholders is not as pronounced for negative transactions as well as for positive transactions.

### Loan Amount

```{python}
avg_loan_amount_cardholders = golden_cardholders["loan_amount"].mean()
avg_loan_amount_non_cardholders = golden_non_cardholders["loan_amount"].mean()

plt.figure()
plt.title("Average Loan Amount by Card Issuance Status")
sns.barplot(
    x=["Cardholders", "Non-Cardholders"],
    y=[avg_loan_amount_cardholders, avg_loan_amount_non_cardholders],
)

plt.ylabel("Average Loan Amount")
plt.show()
```

The average loan amount for cardholders is higher than that of non-cardholders, indicating that non-cardholders tend to have higher loan amounts. Yet, this difference is not as pronounced as with the balance, volume, and transaction count trends and not as significant.

```{python}
golden_record_df.to_parquet("temp/golden_record.parquet")
```

