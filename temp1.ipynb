{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb45ab5",
   "metadata": {},
   "source": [
    "---\n",
    "title: AML Mini-Challenge - Credit Card Affinity Modelling\n",
    "jupyter: python3\n",
    "author: Dominik Filliger & Noah Leuenberger\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "---\n",
    "\n",
    "The task can be found [here](https://spaces.technik.fhnw.ch/storage/uploads/spaces/82/exercises/20240218__AML_Trainingscenter_MiniChallenge_Kreditkarten_Aufgabenstellung-1708412668.pdf).\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "fad7c8ce",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_theme()\n",
    "#plt.style.use('seaborn-white')\n",
    "#plt.style.use('ggplot')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7fe7cb5c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f2a56ec",
   "metadata": {},
   "source": [
    "def plot_categorical_variables(df, categorical_columns, fill_na_value='NA'):\n",
    "    \"\"\"\n",
    "    Plots count plots for categorical variables in a DataFrame, filling NA values with a specified string.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data.\n",
    "    - categorical_vars: list of strings, names of the categorical variables in df to plot.\n",
    "    - fill_na_value: string, the value to use for filling NA values in the categorical variables.\n",
    "    \"\"\"\n",
    "    # Fill NA values in the specified categorical variables\n",
    "    for var in categorical_columns:\n",
    "        if df[var].isna().any():\n",
    "            df[var] = df[var].fillna(fill_na_value)\n",
    "\n",
    "    total = float(len(df))\n",
    "    fig, axes = plt.subplots(nrows=len(categorical_columns), figsize=(14, len(categorical_columns) * 4.5))\n",
    "\n",
    "    if len(categorical_columns) == 1:  # If there's only one categorical variable, wrap axes in a list\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, var in enumerate(categorical_columns):\n",
    "        ax = sns.countplot(x=var, data=df, ax=axes[i], order=df[var].value_counts().index)\n",
    "\n",
    "        axes[i].set_title(f'Distribution of {var}')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_xlabel(var)\n",
    "\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                    height + 3,\n",
    "                    '{:1.2f}%'.format((height / total) * 100),\n",
    "                    ha=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_numerical_distributions(df, numerical_columns, kde=True, bins=30):\n",
    "    \"\"\"\n",
    "    Plots the distribution of all numerical variables in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of rows needed for subplots based on the number of numerical variables\n",
    "    nrows = len(numerical_columns)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=1, figsize=(8, 5 * nrows))\n",
    "\n",
    "\n",
    "    if nrows == 1:  # If there's only one numerical variable, wrap axes in a list\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, var in enumerate(numerical_columns):\n",
    "        sns.histplot(df[var], ax=axes[i], kde=kde, bins=bins)\n",
    "        axes[i].set_title(f'Distribution of {var}')\n",
    "        axes[i].set_xlabel(var)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_date_monthly_counts(df, date_column, title):\n",
    "    \"\"\"\n",
    "    Plots the monthly counts of a date column in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing the data.\n",
    "    - date_column: string, name of the date column in df to plot.\n",
    "    - title: string, title of the plot.\n",
    "    \"\"\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df['month'] = df[date_column].dt.to_period('M')\n",
    "\n",
    "    monthly_counts = df['month'].value_counts().sort_index()\n",
    "    monthly_counts.plot(kind='bar', figsize=(14, 6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def add_percentage_labels(ax, hue_order):\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        width = p.get_width()\n",
    "        x = p.get_x()\n",
    "        y = p.get_y()\n",
    "        label_text = f'{height:.1f}%'\n",
    "        label_x = x + width / 2\n",
    "        label_y = y + height / 2\n",
    "        ax.text(label_x, label_y, label_text, ha='center', va='center', fontsize=9, color='white', weight='bold')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a25f9b3",
   "metadata": {},
   "source": [
    "from collections import OrderedDict\n",
    "data_reduction = OrderedDict()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e96f96e",
   "metadata": {},
   "source": [
    "# Data Import & Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "id": "9752bb01",
   "metadata": {},
   "source": [
    "def remap_values(df, column, mapping):\n",
    "    # assert that all values in the column are in the mapping except for NaN\n",
    "    assert df[column].dropna().isin(mapping.keys()).all()\n",
    "    \n",
    "    df[column] = df[column].map(mapping, na_action='ignore')\n",
    "    return df\n",
    "\n",
    "def map_empty_to_nan(df, column):\n",
    "    if df[column].dtype != 'object':\n",
    "        return df\n",
    "\n",
    "    df[column] = df[column].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    return df\n",
    "\n",
    "def read_csv(file_path, sep=\";\", dtypes=None):\n",
    "    df = pd.read_csv(file_path, sep=sep, dtype=dtypes)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df = map_empty_to_nan(df, col)\n",
    "        \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd12b073",
   "metadata": {},
   "source": [
    "## Accounts"
   ]
  },
  {
   "cell_type": "code",
   "id": "906eea1c",
   "metadata": {},
   "source": [
    "accounts_df = read_csv(\"data/account.csv\")\n",
    "\n",
    "# Translated frequency from Czech to English\n",
    "# according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "accounts_df = remap_values(accounts_df, 'frequency', {\n",
    "    \"POPLATEK MESICNE\": \"MONTHLY_ISSUANCE\",\n",
    "    \"POPLATEK TYDNE\": \"WEEKLY_ISSUANCE\",\n",
    "    \"POPLATEK PO OBRATU\": \"ISSUANCE_AFTER_TRANSACTION\"\n",
    "})\n",
    "\n",
    "accounts_df['date'] = pd.to_datetime(accounts_df['date'], format='%y%m%d')\n",
    "\n",
    "accounts_df.rename(columns={'date': 'account_created',\n",
    "                         'frequency': 'account_frequency'}, inplace=True)\n",
    "\n",
    "data_reduction[\"Total number of accounts\"] = len(accounts_df)\n",
    "accounts_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1d7b39b",
   "metadata": {},
   "source": [
    "# todo add some basic eda here\n",
    "accounts_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "157f0af3",
   "metadata": {},
   "source": [
    "accounts_df.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a70d9cb",
   "metadata": {},
   "source": [
    "plot_categorical_variables(accounts_df, ['account_frequency'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a45b151",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(accounts_df, ['account_created'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "62ed0137",
   "metadata": {},
   "source": [
    "## Clients"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ef08db6",
   "metadata": {},
   "source": [
    "clients_df = read_csv(\"data/client.csv\")\n",
    "\n",
    "def parse_birth_number(birth_number):\n",
    "    birth_number_str = str(birth_number)\n",
    "\n",
    "    # Extract year, month, and day from birth number from string\n",
    "    # according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "    year = int(birth_number_str[:2])\n",
    "    month = int(birth_number_str[2:4])\n",
    "    day = int(birth_number_str[4:6])\n",
    "\n",
    "    # Determine sex based on month and adjust month for female clients\n",
    "    # according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "    if month > 50:\n",
    "        sex = \"Female\"\n",
    "        month -= 50\n",
    "    else:\n",
    "        sex = \"Male\"\n",
    "\n",
    "    # Validate date\n",
    "    assert 1 <= month <= 12\n",
    "    assert 1 <= day <= 31\n",
    "    assert 0 <= year <= 99\n",
    "\n",
    "    if month in [4, 6, 9, 11]:\n",
    "        assert 1 <= day <= 30\n",
    "    elif month == 2:\n",
    "        assert 1 <= day <= 29\n",
    "    else:\n",
    "        assert 1 <= day <= 31\n",
    "\n",
    "    # Assuming all dates are in the 1900s\n",
    "    birth_date = datetime(1900 + year, month, day)\n",
    "    return pd.Series([sex, birth_date])\n",
    "\n",
    "\n",
    "clients_df[['sex', 'birth_date']] = clients_df['birth_number'].apply(parse_birth_number)\n",
    "\n",
    "# Calculate 'age' assuming the reference year is 1999\n",
    "clients_df['age'] = clients_df['birth_date'].apply(lambda x: 1999 - x.year)\n",
    "\n",
    "# Drop 'birth_number' column as it is no longer needed\n",
    "clients_df = clients_df.drop(columns=['birth_number'])\n",
    "\n",
    "clients_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1400d3a7",
   "metadata": {},
   "source": [
    "# todo add some basic eda here\n",
    "clients_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d472ec41",
   "metadata": {},
   "source": [
    "clients_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13dca9a3",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(clients_df, ['birth_date', 'age'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "48980671",
   "metadata": {},
   "source": [
    "## Dispositions"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab216669",
   "metadata": {},
   "source": [
    "dispositions_df = read_csv(\"data/disp.csv\")\n",
    "dispositions_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5eefa7f",
   "metadata": {},
   "source": [
    "dispositions_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d15b66c8",
   "metadata": {},
   "source": [
    "dispositions_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb406031",
   "metadata": {},
   "source": [
    "plot_categorical_variables(dispositions_df, ['type'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c1c9e42",
   "metadata": {},
   "source": [
    "As the goal of this model is to address accounts and not client directly we will focus on the clients which own an account and focus solely on them."
   ]
  },
  {
   "cell_type": "code",
   "id": "feece043",
   "metadata": {},
   "source": [
    "dispositions_df = dispositions_df[dispositions_df['type'] == 'OWNER']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a1f7dbc",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd8f2a06",
   "metadata": {},
   "source": [
    "orders_df = read_csv(\"data/order.csv\")\n",
    "\n",
    "# Translated from Czech to English\n",
    "# according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "orders_df = remap_values(orders_df, 'k_symbol', {\n",
    "    \"POJISTNE\": \"Insurance_Payment\",\n",
    "    \"SIPO\": \"Household\",\n",
    "    \"LEASING\": \"Leasing\",\n",
    "    \"UVER\": \"Loan_Payment\"\n",
    "})\n",
    "\n",
    "orders_df['account_to'] = orders_df['account_to'].astype('category')\n",
    "\n",
    "orders_df = orders_df.rename(columns={'amount': 'debited_amount'})\n",
    "\n",
    "orders_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "200e05d3",
   "metadata": {},
   "source": [
    "orders_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed68b227",
   "metadata": {},
   "source": [
    "orders_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f616234c",
   "metadata": {},
   "source": [
    "orders_df.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6eca37fe",
   "metadata": {},
   "source": [
    "There appear to be as many order ids as there are rows."
   ]
  },
  {
   "cell_type": "code",
   "id": "084eba6b",
   "metadata": {},
   "source": [
    "plot_categorical_variables(orders_df, ['k_symbol', 'bank_to'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0285b20",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(orders_df, ['debited_amount'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc7543f5",
   "metadata": {},
   "source": [
    "## Transactions"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1e04973",
   "metadata": {},
   "source": [
    "# column 8 is the 'bank' column which contains NaNs and must be read as string\n",
    "transactions_df = read_csv(\"data/trans.csv\", dtypes={8: str})\n",
    "\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'], format='%y%m%d')\n",
    "\n",
    "# Translated type, operations and characteristics from Czech to English\n",
    "# according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "transactions_df = remap_values(transactions_df, 'type', {\n",
    "    \"VYBER\": \"Withdrawal\", # Also withdrawal as it is against the documentation present in the dataset\n",
    "    \"PRIJEM\": \"Credit\",\n",
    "    \"VYDAJ\": \"Withdrawal\"\n",
    "})\n",
    "\n",
    "transactions_df = remap_values(transactions_df, 'operation', {\n",
    "    \"VYBER KARTOU\": \"Credit Card Withdrawal\",\n",
    "    \"VKLAD\": \"Credit in Cash\",\n",
    "    \"PREVOD Z UCTU\": \"Collection from Another Bank\",\n",
    "    \"VYBER\": \"Withdrawal in Cash\",\n",
    "    \"PREVOD NA UCET\": \"Remittance to Another Bank\"\n",
    "})\n",
    "\n",
    "transactions_df = remap_values(transactions_df, 'k_symbol', {\n",
    "    \"POJISTNE\": \"Insurance Payment\",\n",
    "    \"SLUZBY\": \"Payment on Statement\",\n",
    "    \"UROK\": \"Interest Credited\",\n",
    "    \"SANKC. UROK\": \"Sanction Interest\",\n",
    "    \"SIPO\": \"Household\",\n",
    "    \"DUCHOD\": \"Old-age Pension\",\n",
    "    \"UVER\": \"Loan Payment\"\n",
    "})\n",
    "\n",
    "# Set the amount to negative for withdrawals and positive for credits\n",
    "transactions_df['amount'] = np.where(transactions_df['type'] == \"Credit\", transactions_df['amount'], -transactions_df['amount'])\n",
    "\n",
    "transactions_df.rename(columns={'type': 'transaction_type'}, inplace=True)\n",
    "\n",
    "transactions_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac0d2b21",
   "metadata": {},
   "source": [
    "transactions_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f513c320",
   "metadata": {},
   "source": [
    "transactions_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a4cab79",
   "metadata": {},
   "source": [
    "plot_categorical_variables(transactions_df, ['transaction_type', 'operation', 'k_symbol'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb04cf0f",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(transactions_df, ['date', 'amount', 'balance'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "48d97b7b",
   "metadata": {},
   "source": [
    "Looking at the distributions of the transaction table we can see that the count of transactions per year increase over time. So we can conclude that the bank has a growing client base.\n",
    "\n",
    "However, the other plots are not very useful. For one the transaction amount seems to be very sparse, ranging from values between -80000 and 80000.\n",
    "\n",
    "The balance distribution also showcases that there are accounts with a negative balance after a transaction, which would only make sense if debt is also included in this value.\n",
    "\n",
    "According to description of the field balance: \"balance after transaction\""
   ]
  },
  {
   "cell_type": "code",
   "id": "8b59f2fd",
   "metadata": {},
   "source": [
    "# Getting a list of unique years from the dataset\n",
    "transactions_df['year'] = transactions_df['date'].dt.year\n",
    "transactions_df['month'] = transactions_df['date'].dt.month\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "\n",
    "years = sorted(transactions_df['year'].unique())\n",
    "\n",
    "# Creating a figure with subplots for each year: one row for each year with two plots (box plot and bar chart)\n",
    "fig, axs = plt.subplots(len(years) * 2, 1, figsize=(15, 6 * len(years)), sharex=True, gridspec_kw={'height_ratios': [3, 1] * len(years)})\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    # Filter transactions for the current year\n",
    "    yearly_transactions = transactions_df[transactions_df['year'] == year]\n",
    "\n",
    "    # Preparing data for the box plot: a list of amounts for each month for the current year\n",
    "    amounts_per_month_yearly = [yearly_transactions[yearly_transactions['month'] == month]['amount'] for month in range(1, 13)]\n",
    "\n",
    "    # Preparing data for the bar chart for the current year\n",
    "    monthly_summary_yearly = yearly_transactions.groupby('month').agg(TotalAmount=('amount', 'sum'), TransactionCount=('amount', 'count')).reset_index()\n",
    "\n",
    "    # Box plot for transaction amounts by month for the current year\n",
    "    axs[i*2].boxplot(amounts_per_month_yearly, patch_artist=True)\n",
    "    # now with seaborn\n",
    "    # sns.boxplot(data=yearly_transactions, x='month', y='amount', ax=axs[i*2])\n",
    "    axs[i*2].set_title(f'Transaction Amounts Per Month in {year} (Box Plot)')\n",
    "    axs[i*2].set_yscale('symlog')\n",
    "    axs[i*2].set_ylabel('Transaction Amounts (log scale)')\n",
    "    axs[i*2].grid(True, which='both')\n",
    "\n",
    "    # Bar chart for transaction count by month for the current year\n",
    "    axs[i*2 + 1].bar(monthly_summary_yearly['month'], monthly_summary_yearly['TransactionCount'], color='tab:red', alpha=0.6)\n",
    "    axs[i*2 + 1].set_ylabel('Transaction Count')\n",
    "    axs[i*2 + 1].grid(True, which='both')\n",
    "\n",
    "# Setting x-ticks and labels for the last bar chart (shared x-axis for all)\n",
    "axs[-1].set_xticks(range(1, 13))\n",
    "axs[-1].set_xticklabels(months)\n",
    "axs[-1].set_xlabel('Month')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ad75da6",
   "metadata": {},
   "source": [
    "# Importing required libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'transactions' DataFrame already contains 'year' and 'month' columns\n",
    "# and is ready for visualization\n",
    "\n",
    "# Getting a list of unique years and defining month labels\n",
    "years = sorted(transactions_df['year'].unique())\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Adjusting the figure layout to place visualizations for each year next to each other\n",
    "fig, axs = plt.subplots(2, len(years), figsize=(40 * len(years) / 2, 30), sharey='row', gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    # Filter transactions for the current year\n",
    "    yearly_transactions = transactions_df[transactions_df['year'] == year]\n",
    "\n",
    "    # Preparing data for the box plot: a list of amounts for each month for the current year\n",
    "    amounts_per_month_yearly = [yearly_transactions[yearly_transactions['month'] == month]['amount'] for month in range(1, 13)]\n",
    "\n",
    "    # Preparing data for the bar chart for the current year\n",
    "    monthly_summary_yearly = yearly_transactions.groupby('month').agg(TotalAmount=('amount', 'sum'), TransactionCount=('amount', 'count')).reset_index()\n",
    "\n",
    "    # Selecting the appropriate axes for multiple or single year scenarios\n",
    "    ax_box = axs[0, i] if len(years) > 1 else axs[0]\n",
    "    ax_bar = axs[1, i] if len(years) > 1 else axs[1]\n",
    "    \n",
    "    ax_box.boxplot(amounts_per_month_yearly, patch_artist=True)\n",
    "    ax_box.set_title(f'{year} (Box Plot)')\n",
    "    ax_box.set_yscale('symlog')\n",
    "    ax_box.set_ylabel('Transaction Amounts (log scale)')\n",
    "    ax_box.grid(True, which='both')\n",
    "\n",
    "    ax_bar.bar(monthly_summary_yearly['month'], monthly_summary_yearly['TransactionCount'], color='tab:red', alpha=0.6)\n",
    "    ax_bar.set_ylabel('Transaction Count')\n",
    "    ax_bar.grid(True, which='both')\n",
    "\n",
    "    # Setting common x-ticks and labels for all axes\n",
    "    ax_bar.set_xticks(range(1, 13))\n",
    "    ax_bar.set_xticklabels(months)\n",
    "\n",
    "# Setting a common x-label for the entire figure\n",
    "fig.text(0.5, 0.04, 'Month', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e118584f",
   "metadata": {},
   "source": [
    "negative_balances = transactions_df[transactions_df['balance'] < 0]\n",
    "plot_numerical_distributions(negative_balances, ['balance', 'amount'])\n",
    "print(f\"Number of transactions with negative balance: {len(negative_balances)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de95b906",
   "metadata": {},
   "source": [
    "There appear to be 2999 transactions which have a negative balance, therefore after the transaction the account balance was negative. This implies that these accounts are in some kind of debt.\n",
    "\n",
    "## Loans"
   ]
  },
  {
   "cell_type": "code",
   "id": "28e647d0",
   "metadata": {},
   "source": [
    "loans_df = read_csv(\"data/loan.csv\")\n",
    "\n",
    "loans_df['date'] = pd.to_datetime(loans_df['date'], format='%y%m%d')\n",
    "\n",
    "loans_df['status'] = loans_df['status'].map({\n",
    "    \"A\": \"Contract finished, no problems\",\n",
    "    \"B\": \"Contract finished, loan not paid\",\n",
    "    \"C\": \"Contract running, OK thus-far\",\n",
    "    \"D\": \"Contract running, client in debt\"\n",
    "})\n",
    "\n",
    "loans_df.rename(columns={\n",
    "    'date': 'granted_date',\n",
    "    'amount': 'amount',\n",
    "    'duration': 'duration',\n",
    "    'payments': 'monthly_payments',\n",
    "    'status': 'status'\n",
    "}, inplace=True)\n",
    "\n",
    "loans_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90384e2c",
   "metadata": {},
   "source": [
    "# todo add some basic eda here\n",
    "loans_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69210e1d",
   "metadata": {},
   "source": [
    "loans_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2a5e124",
   "metadata": {},
   "source": [
    "loans_df.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2389eba",
   "metadata": {},
   "source": [
    "It seems as if one account can have at max one loan."
   ]
  },
  {
   "cell_type": "code",
   "id": "1b49ce7c",
   "metadata": {},
   "source": [
    "plot_categorical_variables(loans_df, ['duration', 'status'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "338dfae0",
   "metadata": {},
   "source": [
    "The distribution of durations seems to be even."
   ]
  },
  {
   "cell_type": "code",
   "id": "cba5fada",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(loans_df, ['granted_date'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0d5e178",
   "metadata": {},
   "source": [
    "## Credit Cards"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b34fcb9",
   "metadata": {},
   "source": [
    "cards_df = read_csv(\"data/card.csv\")\n",
    "\n",
    "cards_df['issued'] = pd.to_datetime(cards_df['issued'], format='%y%m%d %H:%M:%S').dt.date\n",
    "\n",
    "cards_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "398fe81a",
   "metadata": {},
   "source": [
    "cards_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5cc5f90",
   "metadata": {},
   "source": [
    "cards_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0ef0c1d",
   "metadata": {},
   "source": [
    "plot_categorical_variables(cards_df, ['type'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9d61452",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(cards_df, ['issued'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "240ba537",
   "metadata": {},
   "source": [
    "## Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3be2e66",
   "metadata": {},
   "source": [
    "districts_df = read_csv(\"data/district.csv\")\n",
    "\n",
    "# Rename columns\n",
    "# according to https://sorry.vse.cz/~berka/challenge/PAST/index.html\n",
    "districts_df.rename(columns={\n",
    "    'A1': 'district_id',\n",
    "    'A2': 'district_name',\n",
    "    'A3': 'region',\n",
    "    'A4': 'inhabitants',\n",
    "    'A5': 'small_municipalities',\n",
    "    'A6': 'medium_municipalities',\n",
    "    'A7': 'large_municipalities',\n",
    "    'A8': 'huge_municipalities',\n",
    "    'A9': 'cities',\n",
    "    'A10': 'ratio_urban_inhabitants',\n",
    "    'A11': 'average_salary',\n",
    "    'A12': 'unemployment_rate_1995',\n",
    "    'A13': 'unemployment_rate_1996',\n",
    "    'A14': 'entrepreneurs_per_1000_inhabitants',\n",
    "    'A15': 'crimes_committed_1995',\n",
    "    'A16': 'crimes_committed_1996'\n",
    "}, inplace=True)\n",
    "\n",
    "for col in ['unemployment_rate_1995', 'unemployment_rate_1996', 'crimes_committed_1995', 'crimes_committed_1996']:\n",
    "    districts_df[col] = pd.to_numeric(districts_df[col], errors='coerce')\n",
    "\n",
    "districts_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a677e0f7",
   "metadata": {},
   "source": [
    "It appears as if there is 1 null value for unemployment rate in 1995 and crimes committed in 1995."
   ]
  },
  {
   "cell_type": "code",
   "id": "73ee1049",
   "metadata": {},
   "source": [
    "# todo add some basic eda here\n",
    "districts_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b61dc02",
   "metadata": {},
   "source": [
    "districts_df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "220716f9",
   "metadata": {},
   "source": [
    "districts_df.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c33138d6",
   "metadata": {},
   "source": [
    "plot_numerical_distributions(districts_df, ['crimes_committed_1995'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2db8734c",
   "metadata": {},
   "source": [
    "plot_categorical_variables(districts_df, ['region'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7049f48d",
   "metadata": {},
   "source": [
    "We need to differentiate between the domicile of the client and account, as they can be different.\n",
    "\n",
    "# Relationships\n",
    "\n",
    "Following the documentation of the dataset, there are multiple relationships that need to be validated. https://sorry.vse.cz/\\~berka/challenge/PAST/index.html\n",
    "\n",
    "The ERD according to the descriptions on https://sorry.vse.cz/\\~berka/challenge/PAST/index.html\n",
    "\n",
    "[![](https://mermaid.ink/img/pako:eNqtV1Fv4jgQ_itWXu6l7SZ0gQatTsqGdhddCxVQrXSqFJnEgLWJnbOd7bGl__3GTgA3JGyvWh7ajPPNZ898nrHz7MQ8Ic7AIWJI8Urg7JEh-AVhOHkYz9FzaeqfVIKyFcJxzAumIpqg-7_QoxOUNhoNH50jcEL1Q2zQNxo9rAZq8AQrUv45EIaCYEU5Q0MYb-BeCvJPQVi8AZ-RlAVmMUE3u8Gdw0v5L7wdXTeGE6eUWNGExmxa3YIKtY5YkS2IAOBnbbYt7S1hVwsbjmb3k9loPpqMG1YHRPl-bUCSc0lNThqzfYjlpjWWYxVvfqmi2uRamMkTI-LDgySiFsNkOryeNqyei4SI_fIn2voNq1lg9j1SHGBTEtPcxPgZxk7w1tAVve2wTDlWCGdmWkg1WVBFEhRkdWDF_D2Sm2zBU8De402mWcM1FjhWRNCfZt_WkjSfBuNZELYIrQRmcp-qubaAq1XptyXMriqbsmXXVjJD3SVUffhG1ToR-AmnDVCeE1EW52vmO2gmJ9JqQ49TW4IXODWVDCVWPQVLSCqyfE_rYU_SpkltOxkVhYLt_YudZAFrm6hS-XYSNMkLkbG9urdg_C5ZDdcXiFjv1rqutewb7HHaKbxMir2cBjWs7GO2vNztEpB3nKl1ukFVAciGgKTCqpA71pmx6p05mA6b-jIWyaErg9F6wOR2lz3dIHc7XNPN4fkoqxTOEUjkbsbSstN66Nrz6SicN7fsfe-_P3HkVXCGM2KDxmA3wARZlfJMzUNdP8YjvowoW2PoW7iUZ8wvEF-i0WGw2SsrGIXOiFNIHJHRE9S9zRSlKuq6rtb7FRB9QjD8PkpwhJ4ceb7vH_PCy3P95n3UHbfk9hu59dtz_93kKxV5wNCQjD_NeDNrXEL2ioTGPi4tU3LaoRAL3S5eqfmgx2wx0VTDG8r9B7TmFYkkdE-h70ZBOYBmZuDYoWAky1NuajiCNZDI7-oJrWE9F0F_-N03efdavHvN6QGEILkgjBRCRnCwmBzXwr-2QQhAyGvPN88yqqAhRrGgGeho4gnNcz2IU14926tndYBaD9huz8_58_7KPDDtLsa6I4_2lVpHVxfSgSlpSROY5ADeUVVY-46oHQIpeUzNBPqU3nlVlP_PyYZpz-227Mja5SuWLSsqb3wa8wUk0bK3Ie1rTxlsDNfCZvS2PD4Hpv8y9BW2ssY5Z05GRIZpAt8ppuE-OmpNdJ_U0IQscZGaI-0FoLhQfLZhsTNQoiBnTpHrzl593DiDJU4ljOaY_c15tgPpGw8Xd-WnkPkiMhBn8Oz86wyuOhf9bsf96Lndvuu5ff_M2TgDz-1ddK763qXvel237131X86cn4bUvbi67PU6Xt_z3Y--e9ntv_wHEyE3kA?type=png)](https://mermaid.live/edit#pako:eNqtV1Fv4jgQ_itWXu6l7SZ0gQatTsqGdhddCxVQrXSqFJnEgLWJnbOd7bGl__3GTgA3JGyvWh7ajPPNZ898nrHz7MQ8Ic7AIWJI8Urg7JEh-AVhOHkYz9FzaeqfVIKyFcJxzAumIpqg-7_QoxOUNhoNH50jcEL1Q2zQNxo9rAZq8AQrUv45EIaCYEU5Q0MYb-BeCvJPQVi8AZ-RlAVmMUE3u8Gdw0v5L7wdXTeGE6eUWNGExmxa3YIKtY5YkS2IAOBnbbYt7S1hVwsbjmb3k9loPpqMG1YHRPl-bUCSc0lNThqzfYjlpjWWYxVvfqmi2uRamMkTI-LDgySiFsNkOryeNqyei4SI_fIn2voNq1lg9j1SHGBTEtPcxPgZxk7w1tAVve2wTDlWCGdmWkg1WVBFEhRkdWDF_D2Sm2zBU8De402mWcM1FjhWRNCfZt_WkjSfBuNZELYIrQRmcp-qubaAq1XptyXMriqbsmXXVjJD3SVUffhG1ToR-AmnDVCeE1EW52vmO2gmJ9JqQ49TW4IXODWVDCVWPQVLSCqyfE_rYU_SpkltOxkVhYLt_YudZAFrm6hS-XYSNMkLkbG9urdg_C5ZDdcXiFjv1rqutewb7HHaKbxMir2cBjWs7GO2vNztEpB3nKl1ukFVAciGgKTCqpA71pmx6p05mA6b-jIWyaErg9F6wOR2lz3dIHc7XNPN4fkoqxTOEUjkbsbSstN66Nrz6SicN7fsfe-_P3HkVXCGM2KDxmA3wARZlfJMzUNdP8YjvowoW2PoW7iUZ8wvEF-i0WGw2SsrGIXOiFNIHJHRE9S9zRSlKuq6rtb7FRB9QjD8PkpwhJ4ceb7vH_PCy3P95n3UHbfk9hu59dtz_93kKxV5wNCQjD_NeDNrXEL2ioTGPi4tU3LaoRAL3S5eqfmgx2wx0VTDG8r9B7TmFYkkdE-h70ZBOYBmZuDYoWAky1NuajiCNZDI7-oJrWE9F0F_-N03efdavHvN6QGEILkgjBRCRnCwmBzXwr-2QQhAyGvPN88yqqAhRrGgGeho4gnNcz2IU14926tndYBaD9huz8_58_7KPDDtLsa6I4_2lVpHVxfSgSlpSROY5ADeUVVY-46oHQIpeUzNBPqU3nlVlP_PyYZpz-227Mja5SuWLSsqb3wa8wUk0bK3Ie1rTxlsDNfCZvS2PD4Hpv8y9BW2ssY5Z05GRIZpAt8ppuE-OmpNdJ_U0IQscZGaI-0FoLhQfLZhsTNQoiBnTpHrzl593DiDJU4ljOaY_c15tgPpGw8Xd-WnkPkiMhBn8Oz86wyuOhf9bsf96Lndvuu5ff_M2TgDz-1ddK763qXvel237131X86cn4bUvbi67PU6Xt_z3Y--e9ntv_wHEyE3kA)\n",
    "\n",
    "This ERD shows how the data appears in the dataset:\n",
    "\n",
    "[![](https://mermaid.ink/img/pako:eNqtV99P2zAQ_lesvOyFbjCJSq2mSSHlRzRoUVq0F6TITdzWIrEz2xnqgP99ZydNTeIUhOgD5JzvPvvufJ-dJy_hKfHGHhETitcC5_cMwc8PgtnddIGeKlP_pBKUrRFOEl4yFdMU3f5C955f2Sic3HsdcEr1Q2LQFxo9qQda8BQrUv3ZEwaCYEU5QxMYd3CvBPlTEpZswSeUssQsIehiN7hzeKn-BdfhuTOcJKPEiiYwpmt1SyrUJmZlviQCgGfa7Fvae8KuFzYJ57ezebgIZ1PH6oCoaNYGJAWX1OTEme19LBe9sXSrePFmFdW20IWZPTIivt1JIloxzKLJeeRYPRcpEc3yZ9r6hNUsMXuIFQdYRBJamBjPYOwAbwtd09sOq4xjhXBupoVUkyVVJEV-3gbWzA-x3OZLngH2Fm9zzRpssMCJIoL-M_u2laRF5E_nftBTaCUwk02qFtoCrt5Kvy9hdlfZlD27ti4z9F1K1bffVG1SgR9x5oDygoiqOV8z34CYHEirDe2mtgIvcWY6GVqsfvJXkFRk-R6uhz1JX01a28lUUSjY3m_sJAvY2kR1la9nvqu8EBlrqnsNxmeV1XBdQsR6t7br2sq-wXbTTuFlWjblNKhJbXfZimq3S0DecKY22RbVDSAdAUmFVSl3rHNjtZXZjyYuXcYi3asyGL0HTGGr7GGB3O1wTbeA505WKZwjkMjdjJVlp3Wv2osoDBZuyW60__bAkVfDGc6JDZqC7YAJsq7KE5mHdv0Yj_kqpmyDQbdwVZ4p_4r4CoX7QbdXXjIKyogzSByR8SP0vc0UZyo-PT7W9X4FRD8QDH-MEhxBk-OT0WjU5YWXA_3mY9TfjyvukZNbvx2MPky-VvEJMDiS8dOMu1mTCtJUJDB2t7VMy2mHUiy1XLyq5p0es4uJIg13tPtfkOY1iSWop9B3I78aQHMz0HUoGcmLjJsejmENJB6d6gmtYT0XQV9Gp-_yHvZ4D93pAYQghSCMlELGcLCYHLfCP7dBCEDopD_fPM-pAkGME0FzqKOJJzDP7SAOeQ1tr6GlAC0NeH4eDPhTc2UeG7lLsFbksOnUNrq-kI5NS0uawiR78I6qxtp3RO3gS8kTaibQp_TOq6bUTs_P73WyYbWnUWTtcoVlz4qqG5_GXEJJdNn7kPa1pwo2gWuhEw1Tm-NzbPSXoSvYyhrnHXk5ETmmKXynGMG999SGaJ3U0JSscJmZI-0FoLhUfL5liTdWoiRHXlloZa8_brzxCmcSRvUVh4ub6tsn4WxF197LfwBRISI?type=png)](https://mermaid.live/edit#pako:eNqtV99P2zAQ_lesvOyFbjCJSq2mSSHlRzRoUVq0F6TITdzWIrEz2xnqgP99ZydNTeIUhOgD5JzvPvvufJ-dJy_hKfHGHhETitcC5_cMwc8PgtnddIGeKlP_pBKUrRFOEl4yFdMU3f5C955f2Sic3HsdcEr1Q2LQFxo9qQda8BQrUv3ZEwaCYEU5QxMYd3CvBPlTEpZswSeUssQsIehiN7hzeKn-BdfhuTOcJKPEiiYwpmt1SyrUJmZlviQCgGfa7Fvae8KuFzYJ57ezebgIZ1PH6oCoaNYGJAWX1OTEme19LBe9sXSrePFmFdW20IWZPTIivt1JIloxzKLJeeRYPRcpEc3yZ9r6hNUsMXuIFQdYRBJamBjPYOwAbwtd09sOq4xjhXBupoVUkyVVJEV-3gbWzA-x3OZLngH2Fm9zzRpssMCJIoL-M_u2laRF5E_nftBTaCUwk02qFtoCrt5Kvy9hdlfZlD27ti4z9F1K1bffVG1SgR9x5oDygoiqOV8z34CYHEirDe2mtgIvcWY6GVqsfvJXkFRk-R6uhz1JX01a28lUUSjY3m_sJAvY2kR1la9nvqu8EBlrqnsNxmeV1XBdQsR6t7br2sq-wXbTTuFlWjblNKhJbXfZimq3S0DecKY22RbVDSAdAUmFVSl3rHNjtZXZjyYuXcYi3asyGL0HTGGr7GGB3O1wTbeA505WKZwjkMjdjJVlp3Wv2osoDBZuyW60__bAkVfDGc6JDZqC7YAJsq7KE5mHdv0Yj_kqpmyDQbdwVZ4p_4r4CoX7QbdXXjIKyogzSByR8SP0vc0UZyo-PT7W9X4FRD8QDH-MEhxBk-OT0WjU5YWXA_3mY9TfjyvukZNbvx2MPky-VvEJMDiS8dOMu1mTCtJUJDB2t7VMy2mHUiy1XLyq5p0es4uJIg13tPtfkOY1iSWop9B3I78aQHMz0HUoGcmLjJsejmENJB6d6gmtYT0XQV9Gp-_yHvZ4D93pAYQghSCMlELGcLCYHLfCP7dBCEDopD_fPM-pAkGME0FzqKOJJzDP7SAOeQ1tr6GlAC0NeH4eDPhTc2UeG7lLsFbksOnUNrq-kI5NS0uawiR78I6qxtp3RO3gS8kTaibQp_TOq6bUTs_P73WyYbWnUWTtcoVlz4qqG5_GXEJJdNn7kPa1pwo2gWuhEw1Tm-NzbPSXoSvYyhrnHXk5ETmmKXynGMG999SGaJ3U0JSscJmZI-0FoLhUfL5liTdWoiRHXlloZa8_brzxCmcSRvUVh4ub6tsn4WxF197LfwBRISI)"
   ]
  },
  {
   "cell_type": "code",
   "id": "509088ea",
   "metadata": {},
   "source": [
    "# Verify 1:1 relationships between CLIENT, LOAN and DISPOSITION\n",
    "assert dispositions_df['client_id'].is_unique, \"Each client_id should appear exactly once in the DISPOSITION DataFrame.\"\n",
    "assert loans_df['account_id'].is_unique, \"Each account_id should appear exactly once in the LOAN DataFrame.\"\n",
    "\n",
    "# Verify 1:M relationships between ACCOUNT and DISPOSITION\n",
    "#assert dispositions['account_id'].is_unique == False, \"An account_id should appear more than once in the DISPOSITION DataFrame.\"\n",
    "assert dispositions_df['account_id'].is_unique == True, \"An account_id should appear once in the DISPOSITION DataFrame.\"\n",
    "# TODO check if in accordance to decision to remove disponents from dispositions\n",
    "\n",
    "# Verify each district_id in ACCOUNT and CLIENT exists in DISTRICT\n",
    "assert set(accounts_df['district_id']).issubset(\n",
    "    set(districts_df['district_id'])), \"All district_ids in ACCOUNT should exist in DISTRICT.\"\n",
    "assert set(clients_df['district_id']).issubset(\n",
    "    set(districts_df['district_id'])), \"All district_ids in CLIENT should exist in DISTRICT.\"\n",
    "\n",
    "# Verify each account_id in DISPOSITION, ORDER, TRANSACTION, and LOAN exists in ACCOUNT\n",
    "assert set(dispositions_df['account_id']).issubset(\n",
    "    set(accounts_df['account_id'])), \"All account_ids in DISPOSITION should exist in ACCOUNT.\"\n",
    "assert set(orders_df['account_id']).issubset(\n",
    "    set(accounts_df['account_id'])), \"All account_ids in ORDER should exist in ACCOUNT.\"\n",
    "assert set(transactions_df['account_id']).issubset(\n",
    "    set(accounts_df['account_id'])), \"All account_ids in TRANSACTION should exist in ACCOUNT.\"\n",
    "assert set(loans_df['account_id']).issubset(\n",
    "    set(accounts_df['account_id'])), \"All account_ids in LOAN should exist in ACCOUNT.\"\n",
    "\n",
    "# Verify each client_id in DISPOSITION exists in CLIENT\n",
    "assert set(dispositions_df['client_id']).issubset(\n",
    "    set(clients_df['client_id'])), \"All client_ids in DISPOSITION should exist in CLIENT.\"\n",
    "\n",
    "# Verify each disp_id in CARD exists in DISPOSITION\n",
    "assert set(cards_df['disp_id']).issubset(set(dispositions_df['disp_id'])), \"All disp_ids in CARD should exist in DISPOSITION.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "891f4710",
   "metadata": {},
   "source": [
    "# Non-transactional Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "afec192f",
   "metadata": {},
   "source": [
    "orders_pivot_df = orders_df.pivot_table(index='account_id',\n",
    "                                        columns='k_symbol',\n",
    "                                        values='debited_amount',\n",
    "                                        aggfunc='sum',\n",
    "                                        fill_value=0)\n",
    "\n",
    "orders_pivot_df.columns = [f'k_symbol_debited_sum_{col.lower()}' for col in orders_pivot_df.columns]\n",
    "\n",
    "# TODO: find something better than this\n",
    "orders_pivot_df = orders_pivot_df.reset_index() # Use created index as account_id\n",
    "orders_pivot_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf4ec6c4",
   "metadata": {},
   "source": [
    "def merge_non_transactional_data(clients, districts, dispositions, accounts, orders, loans, cards):\n",
    "    # Rename district_id for clarity in clients and accounts DataFrames\n",
    "    clients = clients.rename(columns={'district_id': 'client_district_id'})\n",
    "    accounts = accounts.rename(columns={'district_id': 'account_district_id'})\n",
    "    \n",
    "    # Prepare districts dataframe for merge with prefix for clients and accounts\n",
    "    districts_client_prefixed = districts.add_prefix('client_')\n",
    "    districts_account_prefixed = districts.add_prefix('account_')\n",
    "    \n",
    "    # Merge district information for clients and accounts with prefixed columns\n",
    "    clients_with_districts = pd.merge(clients, districts_client_prefixed, left_on='client_district_id', right_on='client_district_id', how='left')\n",
    "    accounts_with_districts = pd.merge(accounts, districts_account_prefixed, left_on='account_district_id', right_on='account_district_id', how='left')\n",
    "\n",
    "    # Merge cards with dispositions and prefix card-related columns to avoid confusion\n",
    "    cards_prefixed = cards.add_prefix('card_')\n",
    "    dispositions_with_cards = pd.merge(dispositions, cards_prefixed, left_on='disp_id', right_on='card_disp_id', how='left')\n",
    "    \n",
    "    # Merge clients (with district info) with dispositions and cards\n",
    "    # Assuming dispositions might have columns that overlap with clients, prefix those if necessary\n",
    "    clients_dispositions_cards = pd.merge(dispositions_with_cards, clients_with_districts, on='client_id', how='left')\n",
    "    \n",
    "    # Merge the above with accounts (with district info) on account_id\n",
    "    accounts_clients_cards = pd.merge(accounts_with_districts, clients_dispositions_cards, on='account_id', how='left')\n",
    "    \n",
    "    # Merge orders DataFrame, assuming orders might contain columns that could overlap, prefix as needed\n",
    "    orders_prefixed = orders.add_prefix('order_')\n",
    "    comprehensive_df_with_orders = pd.merge(accounts_clients_cards, orders_prefixed, left_on='account_id', right_on='order_account_id', how='left')\n",
    "    \n",
    "    # Merge loans with the comprehensive dataframe (now including orders) on account_id\n",
    "    # Prefix loan-related columns to maintain clarity\n",
    "    loans_prefixed = loans.add_prefix('loan_')\n",
    "    final_df = pd.merge(comprehensive_df_with_orders, loans_prefixed, left_on='account_id', right_on='loan_account_id', how='left')\n",
    "\n",
    "    final_df['account_created'] = pd.to_datetime(final_df['account_created'])\n",
    "    final_df['card_issued'] = pd.to_datetime(final_df['card_issued'])\n",
    "    final_df['has_card'] = final_df['card_issued'].notna()\n",
    "    return final_df\n",
    "\n",
    "non_transactional_df = merge_non_transactional_data(clients_df, districts_df, dispositions_df, accounts_df, orders_pivot_df, loans_df, cards_df)\n",
    "non_transactional_df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11d19ecc",
   "metadata": {},
   "source": [
    "non_transactional_df.to_csv(\"./data/non_transactional.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d668abea",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "### Card Holders"
   ]
  },
  {
   "cell_type": "code",
   "id": "84844c2d",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Number of Clients by Card Type')\n",
    "sns.barplot(x=['No Card', 'Classic/Gold Card Holders', 'Junior Card Holders'], y=[non_transactional_df['card_type'].isna().sum(), non_transactional_df['card_type'].isin(['gold', 'classic']).sum(), non_transactional_df['card_type'].eq('junior').sum()])\n",
    "# ensure that the number of clients is shown on the bars\n",
    "for i, v in enumerate([non_transactional_df['card_type'].isna().sum(), non_transactional_df['card_type'].isin(['gold', 'classic']).sum(), non_transactional_df['card_type'].eq('junior').sum()]):\n",
    "    plt.text(i, v + 10, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2385f94b",
   "metadata": {},
   "source": [
    "Looking at the distribution of card holders in general we can see that the most clients are not in a possession of a credit card."
   ]
  },
  {
   "cell_type": "code",
   "id": "e93cf3df",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f'Distribution of Age for Junior Card Holders\\n total count = {len(non_transactional_df[non_transactional_df[\"card_type\"] == \"junior\"])}')\n",
    "sns.histplot(non_transactional_df[non_transactional_df['card_type'] == 'junior']['age'], kde=True, bins=30)\n",
    "plt.xlabel('Age of Client (presumably in 1999)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc695533",
   "metadata": {},
   "source": [
    "Looking at the age distribution of Junior Card holders paints a picture on this group, however only looking at the current age may be misleading as we need to understand how old they were when the card was issued to determine if they could have been eligble for a Classic/Gold card (at least 18 when the card was issued)."
   ]
  },
  {
   "cell_type": "code",
   "id": "b656e78b",
   "metadata": {},
   "source": [
    "non_transactional_df['card_issued'] = pd.to_datetime(non_transactional_df['card_issued'])\n",
    "\n",
    "non_transactional_df['age_at_card_issuance'] = non_transactional_df['card_issued'] - non_transactional_df['birth_date']\n",
    "non_transactional_df['age_at_card_issuance'] = non_transactional_df['age_at_card_issuance'].dt.days // 365\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f'Distribution of Age at Card Issuance for Junior Card Holders\\n total count = {len(non_transactional_df[non_transactional_df[\"card_type\"] == \"junior\"])}')\n",
    "sns.histplot(non_transactional_df[non_transactional_df['card_type'] == 'junior']['age_at_card_issuance'], kde=True, bins=30)\n",
    "plt.xlabel('Age at Card Issuance')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2ac529e",
   "metadata": {},
   "source": [
    "Here we can see that roughly 1/3 of the Junior Card holders were not of legal age (assuming legal age is 18) when receiving their Junior Card."
   ]
  },
  {
   "cell_type": "code",
   "id": "03108794",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f'Distribution of Age at Card Issuance for All Card Types\\n total count = {len(non_transactional_df)}')\n",
    "sns.histplot(non_transactional_df[non_transactional_df['card_type'] == 'junior']['age_at_card_issuance'], kde=True, bins=10, color='blue', label='Junior Card Holders')\n",
    "sns.histplot(non_transactional_df[non_transactional_df['card_type'] != 'junior']['age_at_card_issuance'], kde=True, bins=30, color='red', label='Non-Junior Card Holders')\n",
    "plt.legend()\n",
    "plt.xlabel('Age at Card Issuance')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d6b1ee2",
   "metadata": {},
   "source": [
    "Comparing the age at issue date between Junior and non-Junior (Classic/Gold) card holders shows that there is no overlap between the two groups, which makes intutively sense.\n",
    "\n",
    "Therefore removing the subset of Junior Cards seems as valid as there is no reason to believe that there are Junior Cards issued wrongly, the subset being relatively small compared to the remaining issued cards and the fact that our target is specifically Classic/Gold Card owners."
   ]
  },
  {
   "cell_type": "code",
   "id": "19fe2180",
   "metadata": {},
   "source": [
    "before_len = len(non_transactional_df)\n",
    "non_transactional_df = non_transactional_df[non_transactional_df['card_type'] != 'junior']\n",
    "data_reduction[\"Junior Card Holders\"] = -(before_len - len(non_transactional_df))\n",
    "del before_len"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2669f60a",
   "metadata": {},
   "source": [
    "Looking at the age distribution of Junior card holders and their occurence in comparison it seems valid to remove them as they are not the target group and make up a small subset of the complete dataset.\n",
    "\n",
    "### Time factors on Card Status\n",
    "\n",
    "The time between creating an account and issuing a card may also be important when filtering customers based on their history. We should avoid filtering out potentially interesting periods and understand how the timespans between account creation and card issuance are distributed."
   ]
  },
  {
   "cell_type": "code",
   "id": "781d7eed",
   "metadata": {},
   "source": [
    "non_transactional_w_cards_df = non_transactional_df[non_transactional_df['card_issued'].notna() & non_transactional_df['account_created'].notna()]\n",
    "non_transactional_w_cards_df['duration_days'] = (non_transactional_w_cards_df['card_issued'] - non_transactional_w_cards_df['account_created']).dt.days\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(non_transactional_w_cards_df['duration_days'], bins=50, edgecolor='black', kde=True)\n",
    "plt.title('Distribution of Duration Between Account Creation and Card Issuance')\n",
    "plt.xlabel('Duration in Days')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ffe5856",
   "metadata": {},
   "source": [
    "The histogram displays a distribution with multiple peaks, indicating that there are several typical time frames for card issuance after account creation. The highest peak occurs within the first 250 days, suggesting that a significant number of cards are issued during this period. The frequency decreases as duration increases, with noticeable peaks that may correspond to specific processing batch cycles or policy changes over time. The distribution also has a long tail, suggesting that in some cases, card issuance can take a very long time.\n",
    "\n",
    "Analyzing the length of time a client has been with the bank in relation to their account creation date and card ownership can provide valuable insights for a bank's customer relationship management and product targeting strategies. Long-standing clients may exhibit different banking behaviors, such as product adoption and loyalty patterns, compared to newer clients."
   ]
  },
  {
   "cell_type": "code",
   "id": "fff2a271",
   "metadata": {},
   "source": [
    "max_account_creation_date = non_transactional_df['card_issued'].max()\n",
    "\n",
    "non_transactional_df['client_tenure_years_relative'] = (max_account_creation_date - non_transactional_df['account_created']).dt.days / 365.25\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.histplot(\n",
    "    data=non_transactional_df, \n",
    "    x='client_tenure_years_relative', \n",
    "    hue='has_card', \n",
    "    multiple='stack', \n",
    "    binwidth=1,\n",
    "    stat=\"percent\"\n",
    ")\n",
    "\n",
    "# Call the function to add labels\n",
    "add_percentage_labels(ax, non_transactional_df['has_card'].unique())\n",
    "\n",
    "# Additional plot formatting\n",
    "plt.title('Client Tenure Relative to Latest Card Issued Date and Card Ownership')\n",
    "plt.xlabel('Client Tenure (Years, Relative to Latest Card Issuance)')\n",
    "plt.ylabel('Percentage of Clients')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b312e854",
   "metadata": {},
   "source": [
    "The bar chart shows the tenure of clients in years, categorized by whether they own a credit card (True) or not (False). Each bar represents the percentage of clients within a specific tenure range, allowing for comparison of the distribution of card ownership among clients with different lengths of association with the bank.\n",
    "\n",
    "### Demographics\n",
    "\n",
    "Using the available demographic data, we can investigate the potential correlation between demographic data and card status. The average salary may indicate a difference between cardholders and non-cardholders, as it is reasonable to assume that cardholders have a higher average salary than non-cardholders."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c520860",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='has_card', y='client_average_salary', data=non_transactional_df)\n",
    "plt.title(\"Average Salary in Client's Region by Card Ownership\")\n",
    "plt.xlabel('Has Card')\n",
    "plt.ylabel('Average Salary')\n",
    "plt.xticks([0, 1], ['No Card Owner', 'Card Owner'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9182aedd",
   "metadata": {},
   "source": [
    "The box plot compares the average salaries of clients who own a credit card with those who do not. Both groups have a substantial overlap in salary ranges, suggesting that while there might be a trend for card owners to have higher salaries, the difference is not significant. The median salary for card owners is slightly higher than that for non-card owners, as indicated by the median line within the respective boxes.\n",
    "\n",
    "Both distributions have outliers on the higher end, indicating that some individuals have salaries significantly above the average in both groups. However, these outliers do not dominate the general trend.\n",
    "\n",
    "It should also be noted that this plot assumes that the average salary of the region's clients remained constant over the years, which is unlikely to be true.\n",
    "\n",
    "The group of bar charts represents the distribution of credit card ownership across various demographics, showing the percentage of clients with and without cards within different age groups, sexes, and regions."
   ]
  },
  {
   "cell_type": "code",
   "id": "77dde38d",
   "metadata": {},
   "source": [
    "non_transactional_df['age_group'] = pd.cut(non_transactional_df['age'], bins=[0, 25, 40, 55, 70, 100], labels=['<25', '25-40', '40-55', '55-70', '>70'])\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Age Group\n",
    "plt.subplot(3, 1, 1)\n",
    "age_group_counts = non_transactional_df.groupby(['age_group', 'has_card']).size().unstack(fill_value=0)\n",
    "age_group_percentages = (age_group_counts.T / age_group_counts.sum(axis=1)).T * 100\n",
    "age_group_plot = age_group_percentages.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "age_group_plot.set_title('Card Ownership by Age Group')\n",
    "age_group_plot.set_ylabel('Percentage')\n",
    "add_percentage_labels(age_group_plot, non_transactional_df['has_card'].unique())\n",
    "\n",
    "# Sex\n",
    "plt.subplot(3, 1, 2)\n",
    "sex_counts = non_transactional_df.groupby(['sex', 'has_card']).size().unstack(fill_value=0)\n",
    "sex_percentages = (sex_counts.T / sex_counts.sum(axis=1)).T * 100\n",
    "sex_plot = sex_percentages.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "sex_plot.set_title('Card Ownership by Sex')\n",
    "sex_plot.set_ylabel('Percentage')\n",
    "add_percentage_labels(sex_plot, non_transactional_df['has_card'].unique())\n",
    "\n",
    "# Client Region\n",
    "plt.subplot(3, 1, 3)\n",
    "region_counts = non_transactional_df.groupby(['client_region', 'has_card']).size().unstack(fill_value=0)\n",
    "region_percentages = (region_counts.T / region_counts.sum(axis=1)).T * 100\n",
    "region_plot = region_percentages.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "region_plot.set_title('Card Ownership by Client Region')\n",
    "region_plot.set_ylabel('Percentage')\n",
    "region_plot.tick_params(axis='x', rotation=45)\n",
    "add_percentage_labels(region_plot, non_transactional_df['has_card'].unique())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8fe4a5a4",
   "metadata": {},
   "source": [
    "**Card Ownership by Age Group:** The bar chart displays the proportion of cardholders in different age groups. The percentage of cardholders is lowest in the age group of over 70, followed by the age group of 55-70, indicating that card ownership is more prevalent among younger demographics.\n",
    "\n",
    "**Card Ownership by Sex:** The bar chart shows the breakdown of card ownership by sex. The data reveals that the percentage of cardholders is comparable between both sexes, and no significant difference is present.\n",
    "\n",
    "**Card Ownership by Region** The bar chart at the bottom illustrates card ownership across different regions, showing a relatively consistent pattern among most regions.\n",
    "\n",
    "### Impact of Loans / Debt"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce66f8f9",
   "metadata": {},
   "source": [
    "simplified_loan_status_mapping = {\n",
    "    \"Contract finished, no problems\": \"Finished\",\n",
    "    \"Contract finished, loan not paid\": \"Not Paid\",\n",
    "    \"Contract running, OK thus-far\": \"Running\",\n",
    "    \"Contract running, client in debt\": \"In Debt\",\n",
    "    \"No Loan\": \"No Loan\"\n",
    "}\n",
    "\n",
    "non_transactional_df['loan_status_simplified'] = non_transactional_df['loan_status'].map(simplified_loan_status_mapping)\n",
    "\n",
    "## this variable wants to kill itself\n",
    "loan_status_simplified_card_ownership_counts = non_transactional_df.groupby(['loan_status_simplified', 'has_card']).size().unstack(fill_value=0)\n",
    "loan_status_simplified_card_ownership_percentages = (loan_status_simplified_card_ownership_counts.T / loan_status_simplified_card_ownership_counts.sum(axis=1)).T * 100\n",
    "\n",
    "loan_status_simplified_card_ownership_percentages.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.title('Interaction Between Simplified Loan Status and Card Ownership')\n",
    "plt.xlabel('Simplified Loan Status')\n",
    "plt.ylabel('Percentage of Clients')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Has Card', labels=['No Card', 'Has Card'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cefd9c68",
   "metadata": {},
   "source": [
    "# Transactional Data\n",
    "\n",
    "## Set artificial issue date for non-card holders"
   ]
  },
  {
   "cell_type": "code",
   "id": "9646f8da",
   "metadata": {},
   "source": [
    "def add_months_since_account_to_card(df):\n",
    "    df['months_since_account_to_card'] = df.apply(\n",
    "        lambda row: (row['card_issued'].to_period('M') - row['account_created'].to_period('M')).n\n",
    "        if pd.notnull(row['card_issued']) and pd.notnull(row['account_created']) else np.nan, axis=1)\n",
    "    return df\n",
    "\n",
    "def filter_clients_without_sufficient_history(non_transactional_df, min_history_months=25):\n",
    "    if 'months_since_account_to_card' not in non_transactional_df.columns:\n",
    "        print(\"Warning: months_since_account_to_card column not found. Calculating history length.\")\n",
    "        non_transactional_df = add_months_since_account_to_card(non_transactional_df)\n",
    "\n",
    "    count_before = len(non_transactional_df)\n",
    "    filtered_df = non_transactional_df[non_transactional_df['months_since_account_to_card'].isnull() | (non_transactional_df['months_since_account_to_card'] >= min_history_months)]\n",
    "    print(f\"Filtered out {count_before - len(filtered_df)} records with less than {min_history_months} months of history. Percentage: {(count_before - len(filtered_df)) / count_before * 100:.2f}%.\")\n",
    "    return filtered_df\n",
    "\n",
    "before_len = len(non_transactional_df)\n",
    "non_transactional_w_sufficient_history_df = filter_clients_without_sufficient_history(non_transactional_df)\n",
    "data_reduction[\"Clients without sufficient history\"] = -(before_len - len(non_transactional_w_sufficient_history_df))\n",
    "del before_len"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b62314d8",
   "metadata": {},
   "source": [
    "non_transactional_w_card_df = non_transactional_w_sufficient_history_df.dropna(subset=['card_issued']).copy()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(non_transactional_w_card_df['months_since_account_to_card'], kde=True, bins=30)\n",
    "plt.title('Distribution of Months from Account Creation to Card Issuance')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac04056c",
   "metadata": {},
   "source": [
    "\n",
    "### DEPENDENCY TODO REMOVE FOR MERGE\n",
    "import json\n",
    "# save transactions_df to temp as parquet\n",
    "\n",
    "transactions_df.to_parquet(\"temp/transactions.parquet\")\n",
    "non_transactional_w_sufficient_history_df.to_parquet(\"temp/non_transactional_w_sufficient_history.parquet\")\n",
    "accounts_df.to_parquet(\"temp/accounts.parquet\")\n",
    "\n",
    "# save data reduction\n",
    "with open(\"temp/data_reduction.json\", \"w\") as f:\n",
    "    json.dump(data_reduction, f)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/dmnk/PycharmProjects/fhnw-aml-mc/venv/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
